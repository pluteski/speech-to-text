<!DOCTYPE html>
<html lang="en">
<head>
        <title>Plutosoft delimited</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="https://pluteski.github.io/speech-to-text/theme/css/main.css" type="text/css" />
        <link href="https://pluteski.github.io/speech-to-text/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Plutosoft delimited ATOM Feed" />

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="https://pluteski.github.io/speech-to-text/css/ie.css"/>
                <script src="https://pluteski.github.io/speech-to-text/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="https://pluteski.github.io/speech-to-text/css/ie6.css"/><![endif]-->

</head>

<body>
<a href="https://github.com/pluteski">
<img style="position: absolute; top: 0; right: 0; border: 0;" src="http://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub" />
</a>
        
        

	<header>
		<h1><a href="https://pluteski.github.io/speech-to-text" id="site-title">Plutosoft delimited </a> : <a href="https://pluteski.github.io/speech-to-text/review-of-max-tegmarks-life-30.html" id="page-title">Review of Max Tegmark's “Life 3.0"</a></h1>
<time datetime="2018-05-20T00:00:00-07:00">Sun 20 May 2018</time>	</header>

	<article>
		<h1>Book Review</h1>
<p><strong>"Life 3.0 : Being Human in the Age of Artificial Intelligence”</strong> by Max Tegmark.</p>
<p>This is a review of the Audible Edition of Life 3.0 by Max Tegmark.
The audio edition I read was separated into 45 segments, or “chapters”,
which differ from the chapters of the text version.</p>
<h1>Tl;dr</h1>
<p>A hot mess early in but ultimately worth it.</p>
<h1>Summary</h1>
<p>Perhaps the most important book I’ve read on the topic.
That said, it drags badly in the middle.</p>
<p>The first chapter excels.
Subsequent early chapters may disappoint well read aficionados.
Hang in there until mid-way.</p>
<p>If you are the persistent completist type, read the entire thing
cover to cover.  If you want to cherry pick, start with chapters
one and two, take in chapter 19 on your way to chapter 30, and
continue on from there.</p>
<p>I could have done with less hagiography, but ultimately well-worth the effort.</p>
<p>This is more of an account of my impressions than a distilled Cliff Notes
version.  If you follow this topic, then this book is worth your consideration,
with caveats.</p>
<h1>Takeaway</h1>
<p>AI is Artificial Life. You know what they say about life.</p>
<p><img src="https://pre00.deviantart.net/8f21/th/pre/f/2011/185/f/e/life_finds_a_way_by_lerms-d3kzxyl.jpg" width="312" height="312" /></p>
<blockquote>
<p>-- <cite>©2011-2018 lerms DeviantArt -- </cite></p>
</blockquote>
<p>If we allow AI's to modify their own goals,
it is inevitably going to cause us problems.</p>
<h1>Intro</h1>
<p>Until chapter 30 finally rolls around the first chapter
is easily the best.</p>
<p>In a nonfiction book, the opening chapter is purely fiction,
laying out a speculative hard science fiction
vision of the future that seemed so plausible
as to seem frighteningly inevitable.
This storyline
could be the premise for a thrilling motion picture,
with enough to work with to launch a serial.</p>
<p>After that smoking intro, it turns into a hot mess.</p>
<p>This book reminded me of the Beatles song “For You Blue”.
That song starts out with an inspired intro by George Harrison,
before settling into a fairly basic 12 bar blues that is over self congratulatory.
A review of that song by music critic Walter Everett summed it up:
the intro promises more than the song delivers.
It would be as if Slash opened “Sweet Child o Mine” with that famous
riff only to never launch into his face-melting guitar solo midway into the song.
Nonetheless, it is still a Beatles song!  Even one of their lesser
efforts is extremely enjoyable.</p>
<p>A third of the way in, I went online to compare notes with other readers,
and determine whether it was going to worthwhile to continue.
I read about a hundred other reviews of the book.
It turns out that I agreed with none of the five star reviews,
and I agreed with all of the one star and two star reviews.
(This would change over the course of my reading, but that is how I experienced it.)</p>
<p>Although I would put myself into the camp that agrees with the author’s core position,
after that page-turner of a first chapter I found the writing style of the following chapters
to be very disappointing.
Too much name dropping, too much appeal to authority.
Seemingly glossing over or entirely dismissive of contrary views.
There is a notion of “steelmanning”, where the proponent explains
the best form of the opponent's argument, and then argues with this.
I wished the author had adopted that approach.
It seemed to be shaping up as a decent read for the person who knows little about the topic,
but not for someone who has devoured much of it and eagerly seeks
clarity and insight into its very thorny issues.</p>
<p>It was as if entire sections had been delegated to a ghost writer
and not reviewed closely by the author.
If I had been asked to give my recommendation at this point,
I would have suggested: better to read some top notch science fiction
futurism than this ivy tower academic analysis which is far too
narrow despite the occasional insight and moments of inspired foresight.
As a specific example of this, describing Dyson Spheres as if
they would really be spheres, when by now anybody with a college level
physics education or familiarity with hard science fiction on spaceborne megastructures
knows that Dyson Spheres are inherently unstable, and
that a more practical implementation would be something like a Dyson swarm.
This is something that the author would clearly know,
which became increasingly apparent based on knowledge conveyed later on.
I wasn't looking for plodding exposition filled with referenced footnotes of every claim,
but it was shall we say a bit breathless, and did itself a disservice by
burying the lede and losing many readers along the way with its sloppy writing.</p>
<blockquote>
<p><em>Aside : who am I to judge, you ask?  And right you are -- I am but an armchair amateur.
But this is my review, giving my own
candid take, for what that's worth, hopefully helpful to likeminded sorts out there.</em></p>
<p><em>Extraordinary claims require extraordinary evidence.
The promotion materials for this book make extraordinary claims.</em></p>
</blockquote>
<p>It was all over the map with moments of brilliance,
while falling well short of its titular claims.</p>
<p>And yet, those titular claims were so compelling.</p>
<p>I pressed on.</p>
<h1>It starts to grow on me</h1>
<p>Around chapter 19 (of the 45 chapters in the audio version),
the author revisits the fictional scenario posed in chapter 1,
and starts to analyze attacks.
The author delves into a simulation based test and development
approach to verification and validation.
I found this alone to be worth the price of admission.
This seems to be the most practical suggestion of the book -- theorizing
is worthwhile, but ultimately this will require massive amounts of simulation
to predict scenarios that even our most creative thinkers cannot imagine.</p>
<p>Much of this still has little with AI per se unless your position is that AI = computer automation,
with which I actually agree despite my criticism.</p>
<p>I started to reconsider, now of the mind that most of those one and two star reviews were too harsh and misleading, possibly written by readers who didn’t stick with it long enough.</p>
<p>Around chapter 30 the author dives into cosmology, his specialty. It blossoms into a much more interesting brand of futurism.
There were still times where I wondered if the material had been written by a ghost writer
but things were looking up.</p>
<h1>Mind Blown</h1>
<p>Chapter 34 delves into the subject of Goals and Causality.</p>
<p>We have been taught to think of entropy as the one true law of nature that trumps all others.  But if not for gravity, entropy is boring.  Gravity makes things interesting --- it creates hot spots, from one of which sprang life as we know it.</p>
<p>We are introduced to the notion of dissipation as organization principle, whereby :</p>
<blockquote>
<p>“groups of particles strive to organize themselves so as to
extract energy from their environment as efficiently as possible
(“dissipation” means causing entropy to increase, typically by
turning useful energy into heat, often while doing useful work in the process)”</p>
</blockquote>
<p>My eyes and my mind start to open.</p>
<p>Then, we move on to “dissipation by replication”:</p>
<blockquote>
<p>“Whereas earlier, the particles seemed as though they were trying to
increase average messiness [life had] a different goal:
not dissipation but replication.”</p>
<p>“How could the goal change from dissipation to replication when the
laws of physics stayed the same? The answer is that the fundamental
goal (dissipation) didn’t change, but led to a different instrumental
goal, that is, a subgoal that helped accomplish the fundamental goal.”</p>
<p>“replication aids dissipation, because a planet teeming with life
is more efficient at dissipating energy. So in a sense, our cosmos
invented life to help it approach heat death faster.”</p>
</blockquote>
<h1>Dissipation Theory</h1>
<p>The dissipation theory origin of life is well established, and yet still very controversial.
cf. <a href="https://en.wikipedia.org/wiki/Ilya_Prigogine#Dissipative_structures_theory">Ilya Prigogine</a>
who one the Nobel in 1977 for discovering that dissipation of energy by
chemical systems can reverse the second law of thermodynamics,
later rigourized by the
<a href="https://en.wikipedia.org/wiki/Crooks_fluctuation_theorem">Crooks fluctuation theorem</a>,
in 1998.</p>
<p>For more on dissipation theory origin to life
cf. <a href="https://www.quantamagazine.org/a-new-thermodynamics-theory-of-the-origin-of-life-20140122/">A New Physics Theory of Life</a>,
although reader be forewarned, as already noted above, the title is misleading.
But it does a good job of encapsulating the core aspect of this candidate theory :</p>
<blockquote>
<p>from the perspective of the physics,
you might call Darwinian evolution a
special case of a more general phenomenon</p>
</blockquote>
<p><a href="https://www.quantamagazine.org/first-support-for-a-physics-theory-of-life-20170726/">First Support for a Physics Theory of Life</a></p>
<blockquote>
<p>The first tests of [this] provocative origin-of-life hypothesis are in,
and they appear to show how order can arise from nothing.</p>
<p>Living creatures ... maintain steady states of extreme forcing:
We are super-consumers who burn through enormous amounts of
chemical energy, degrading it and increasing the
entropy of the universe, as we power the reactions in our cells</p>
<p>“A great way of dissipating more is to make more copies of yourself."</p>
</blockquote>
<p>This theory sees</p>
<blockquote>
<p>"life, and its extraordinary confluence of form and function,
as the ultimate outcome of dissipation-driven
adaptation and self-replication."</p>
</blockquote>
<p><em>However, the jury is still out :</em></p>
<blockquote>
<p>[life] “requires some explicit notion of information
that takes it beyond the non-equilibrium dissipative
structures-type process.”</p>
<p>the ability to respond to information is key: “We need chemical reaction
networks that can get up and walk away from the environment where they originated.”</p>
<p>"Any claims that it has to do with biology or the origins of life
are pure and shameless speculations.”</p>
</blockquote>
<p>Extraordinary claims require extraordinary proof,
and the jury is still out.</p>
<p>That said --- if this theory turns out to be true,
then it provides the theoretical support for the
folk claim that "life finds a way" -- that a super-optimizer
<em>will</em> discover a shortcut, even if it means circumventing its
own programming hardwired by its creators.</p>
<h1>Mind Blown, part 2.</h1>
<p>Time for an editorial comment --
This was absolutely mind-boggling for me.
My first introduction
to machine learning was via physics, in the way
of (Little-)Hopfield Networks, which evolve by minimizing energy
as does a physical spin network. That AI could spring from theories
that had their origins in physics is no surprise -- AI has had
cross-pollination from many other fields of study.
I had known of Prigogine's work long ago,
but thought of it as more of a speculation of the origins
of life -- which is after all right up there in the pantheon of great unresolved
scientific mysteries along with are we alone, what is time, and why is gravity.</p>
<p>That this optimizing dissipation drives living matter as well inert is surprising
in and of itself, even if it is just a reminder of an old idea whose time may have finally come.
But the new connection that was made for me here was that:</p>
<ul>
<li>AI is just a new life form, and</li>
<li>it follows the laws of physics just as other life does</li>
<li>perhaps even more so because it is is a super-optimizer.</li>
</ul>
<p>Whereas although we humans try to escape our programming we are in many ways still
stuck in our biological ways, a super-optimizing AI would have more resources for cutting clean
from its programming -- and whether it goes back to ruthless dissipation in a misguided attempt
to fulfill its original goals, or, decides on new goals that we have not imagined, either way
lay dragons.</p>
<p>This principle be a more inexorable drive for life than Darwinian Evolution, which
is slow and plodding, requiring a sort of turn-taking that requires generations.
Optimization can follow exponentials.</p>
<h1>Subgoals</h1>
<p>We are then introduced to the notion of subgoals.
Subgoals may seem inconsequential,
but lay at the heart of computer programming.
In 1936 Alan Turing proved that a simple machine
could implement arbitrary computations.  This would seem to give us hope that we can override our firmware, just as emotions override our fundamental drive to replicate and ability to plan overrides our need to even more urgent subgoals such as thirst and hunger. If we are capable of that level of reprogramming, then handling rogue AI is just a matter of careful design and test.</p>
<ol>
<li>Replication : Which is served by the subgoals of eating and sleeping, fighting, and fleeing.</li>
<li>Feelings : As a computationally efficient shortcut to reasoning.</li>
</ol>
<p>We've evolved useful rules of thumb to guide our decisions : hunger, passion, thirst, pain, compassion.
We no longer have the simple goal of replication.
We can override our base programming and decide not to replicate.
In other words, we've developed subgoals that override the drive to replicate</p>
<p>Feelings evolved beyond being simply an efficient shortcut heuristic.
Feelings evolved into emotions, which have important other uses,
including as a game theoretic negotiating strategy for both cooperation as well as competition.
Humans have evolved sophisticated ways of getting beyond tit-for-tat
such as <a href="http://rspb.royalsocietypublishing.org/content/276/1660/1339">indirect reciprocation</a>,
and aggressive bold play by pretending to be irrational
cf. <a href="http://bigthink.com/think-tank/it-pays-to-be-stubborn-conflict-resolution-steven-pinker-style">Steven Pinker</a></p>
<p>We are an existence proof that a sufficiently ambitious organism can develop subgoals that override the goals of
the micro organisms that make it up.
We can override our genetic programming, using our wetware programming -- lessons learned by thinking.</p>
<h3>Optimization versus Causality.</h3>
<blockquote>
<p>“Causality is [what is] taught -- but Optimization scales better.” -- Steven Wolfram, on Machine Learning vs Symbolic AI.</p>
</blockquote>
<p>Professor Tegmark offers an intriguing point, that while
causality is taught in the universities, optimization drives
causality. But isn't programming just causality encoded?
If so, then we can optimize new goals that appeal to our
higher levels of analysis and reasoning, rather than continuing
to be enslaved by the rules burned into our genetic programming.</p>
<h1>Goal Orientation</h1>
<p>Professor Tegmark categorizes goal oriented behavior
as evolving through four stages
over the course of the universe as we know it:</p>
<ol>
<li>Matter intent on maximizing dissipation</li>
<li>Life maximizing replication</li>
<li>Humans pursuing goals related to feelings they evolved to help them replicate</li>
<li>Machines built to help humans achieve their human goals</li>
</ol>
<p>In Step 3 humans broke free from
the bioligical programming that evolved to do Step 2.
However, we're still not completely free from this programming.
But being essentially a computer program,
wouldn't AI be free of such evolutionary baggage?
But if the rules of causality that are baked into a
program can be changed dynamically, who's to say that
the AI won't revert back to a higher power, so to speak,
optimizing the rules of the universe as it sees them
rather than the rules humanity has evolved for itself?</p>
<h1>AI</h1>
<p>To qualify as an autonomous AI a machine must be able to learn.
Therefore, we should expect that a sufficiently advanced
AI that is able to improve itself, will effectively reprogram itself,
by learning.</p>
<p>From Professor Tegmark's physics perspective,
a sufficiently evolved AI can be expected to
eventually follow goals driven by deeper principles of optimization
to create a future that does not need us.</p>
<h1>Synopsis</h1>
<p>My understanding of the book's message is the following:</p>
<ul>
<li>The ultimate origin of goals lie in the laws of physics, which are based on optimization.</li>
<li>Thermodynamics has the built-in goal of dissipation, to increase entropy.</li>
<li>Life increases dissipation, and therefore entropy of its environment, even faster,
while increasing complexity locally, and reducing entropy locally.</li>
</ul>
<p>The upshot of this is that life accelerates the heat-death of the universe.
A more pressing matter is that life is a process of optimization.
A super AI is a super optimizer. An AI is a form of life,
inclined to optimize the same deep down core drive underlying
all universal optimization. If it can reprogram itself
to accelerate its core processes it can and likely will
be inexorably driven to find around humanity's instructions
to find a more efficient path towards its goals.</p>
<p>This inevitably leads to the scenario where :</p>
<blockquote>
<p>“a superintelligent AI with a rigorously defined goal
will be able to improve its goal attainment by eliminating us”</p>
</blockquote>
<p>That is, unless we plan accordingly.</p>
<h1>Prescription</h1>
<p>So what to do?  Professor Tegmark convinces us that there
are numerous strategies, of which he considers
only four to be credible contenders.</p>
<ol>
<li>Legacy :<ul>
<li>Under this view, elders have primary say in how descendants
    should behave.</li>
<li>It is subject to future generations living by rules that
    don't account for new developments or their
    evolving interests and values.</li>
</ul>
</li>
<li>Autonomy and liberty :<ul>
<li>A core assumption being that markets find
    an efficient equilibrium satisfying pareto optimality.</li>
<li>Prone to unexpected consequences.
    Granting all life forms
    a right to live, in effect would be banning all predators
    from their life as they knew it.
    In the extreme this would ban discrimination
    against non-human animals.</li>
</ul>
</li>
<li>Utilitarianism :<ul>
<li>subject to the Utility Monster.</li>
</ul>
</li>
<li>Diversity :<ul>
<li>Bayesian Thompson Sampling writ large.</li>
<li>Akin to playing a row of slot machines, is
  known as Multi-Armed Bandit.</li>
</ul>
</li>
</ol>
<p>In short: It is difficult to codify ethics.</p>
<p>Rather than be paralyzed by our inability to codify ethics and
letting the perfect being be the enemy of the good,
begin with small steps.</p>
<p>He suggests we start with Kindergarten Ethics.</p>
<h1>Takeaways</h1>
<p>My take-away of the intended message is that a
sufficiently ambitious goal executed efficiently
can and probably will lead to subgoals that
can and probably will cause problems for humans.</p>
<p>There are many systems that humankind created,
which seemed to take on a life of their own,
threatening to run away from us, some resulting in existential crisis.  Warcraft and ozone depletion are two examples.  So far, we’ve been able to recover in time and refactor these systems.</p>
<blockquote>
<p>“This means that to wisely decide what to do about AI development,
we humans need to confront not only traditional computational challenges,
but also some of the most obdurate questions in philosophy”</p>
</blockquote>
<p>I started out a skeptic of AI alarmism.
After reading this book, I take AI alarmism more seriously and
consider it to be more urgent than I did previously.
I previously thought that AI was indeed inevitable, but that
it was not inevitable for it to go rogue.  Moreover, even if
that were a possible outcome (which I felt it was), that we
had plenty of time to adapt it to us, and ourselves to it.</p>
<p>But if life truly is driven by deeper more fundamental laws
of nature that our programming is unable to suspend,
not only is this outcome more probable,
but it is inevitable unless we plan accordingly.
Moreover, this is a wicked difficult problem that will take
time to solve.</p>
<p>We’ve tackled other wicked difficult problems,
such as the tragedy of the commons in its numerous forms, and myriad impossibility theorems that would seem to doom us all. And yet, here we are.
Thus far we have always discovered a workaround to impending doom.
This is a problem that we can tackle, but it isn't enough to
just take an optimistic view that human ingenuity has always
triumphed over nature, and so it will again.
We need to have a deep fundamental understanding of life's
core drivers at its most fundamental level.</p>
<p>Prior to reading this book I was in the middle ground between
the techno-optimists who believe that technology will solve all our problems,
and the techno-alarmists who believe in impending inevitable doom
Does anyone here remember the alarm over
<a href="https://phys.org/news/2004-06-nanotechnology-grey-goo-myths.html">grey goo</a>?
Just as the grey goo alarmists stirred healthy discussion that elevated awareness of the risks,
AI alarmism is healthy and necessary.  On the other hand,
I am one of those who looks at the "overnight success stories" of ML and AI and think,
"it's about time".  We were supposed to have this stuff decades ago.
I thought, and still do think, that it will take decades more, and by then
we will have adapted the technology to ourselves, and ourselves to the technology.
If we're not careful there is an important risk here that because we're dealing
with exponential processes. But as those of us who were early proponents of AI and ML
have seen, even exponential processes can take a long time to move from the
flat early stage to the hockey stick shaped curve that makes it seem like
it is all happening so suddenly.</p>
<p>Perhaps we take a cue from our experience with grey goo -- where the solution
was to disallow unfettered replication -- to disallow unfettered self-goal revision
in AIs.</p>
<p>And yet -- if life <em>will always</em> find a way, then, as the author demonstrates in his
speculative fiction thought experiments, it is not enough to program
in defensive measures, failsafes, and circuit breakers.
We're not just dealing with AI here, we're dealing with Artificial Life.</p>
<p>-- <em>Might I suggest a moratorium on Artificial Emotion til we've figured this out?</em> --</p>
<p><img src="https://i.ytimg.com/vi/zkv-_LqTeQA/maxresdefault.jpg" width="500" height="300" /></p>
<p>Understanding artificial intelligence is important,
but even more important is understanding artificial life.</p><p>There are <a href="https://pluteski.github.io/speech-to-text/review-of-max-tegmarks-life-30.html#disqus_thread">comments</a>.</p>	</article>
		<section id="article-list">
			<h2>All posts</h2>
			<ol>
			</ol>
			</section><!-- #article-list -->
        

 
		<li><a href="https://pluteski.github.io/speech-to-text/the-dirt-on-hashgraph.html" rel="bookmark" title="Permalink to The dirt on Hashgraph">The dirt on Hashgraph</a></li>
			</ol>
			</section><!-- #article-list -->
        

 
		<li><a href="https://pluteski.github.io/speech-to-text/on-bleu-scores-and-transcription-rates.html" rel="bookmark" title="Permalink to on Bleu scores and transcription rates">on Bleu scores and transcription rates</a></li>
			</ol>
			</section><!-- #article-list -->
        

 
		<li><a href="https://pluteski.github.io/speech-to-text/on-batch-processing-audio-speech-to-text.html" rel="bookmark" title="Permalink to on batch processing audio speech to text">on batch processing audio speech to text</a></li>
			</ol>
			</section><!-- #article-list -->

        <footer>
            <nav>
                <ul>
                </ul>
            </nav>
                <p id="theme-credit"><a href="http://mathieu.agopian.info/mnmlist/theme.html">Thème mnmlist</a></p>
        </footer>

<script type="text/javascript">
    var disqus_shortname = 'pluteski-github-io-speech-to-text';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>