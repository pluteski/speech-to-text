<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Plutoware delimited - misc</title><link href="https://pluteski.github.io/speech-to-text/" rel="alternate"></link><link href="https://pluteski.github.io/speech-to-text/feeds/misc.atom.xml" rel="self"></link><id>https://pluteski.github.io/speech-to-text/</id><updated>2018-07-29T00:00:00-07:00</updated><entry><title>How to showcase your Apache Spark skills</title><link href="https://pluteski.github.io/speech-to-text/how-to-showcase-your-apache-spark-skills.html" rel="alternate"></link><published>2018-07-29T00:00:00-07:00</published><updated>2018-07-29T00:00:00-07:00</updated><author><name>Mark Plutowski</name></author><id>tag:pluteski.github.io,2018-07-29:/speech-to-text/how-to-showcase-your-apache-spark-skills.html</id><summary type="html">&lt;h1&gt;How to spotlight your Apache Spark skills&lt;/h1&gt;
&lt;p&gt;&lt;img align="right" hspace=10x src="http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/spark/L4.UI.DAG.png" alt="Spark UI DAG" width="230px"
/&gt;
How do you prove your capability as a Apache Spark data scientist when you don’t have much to show? Perhaps this is because you don’t have much experience. Perhaps it is because the work you do cannot be shown. 
You may …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;How to spotlight your Apache Spark skills&lt;/h1&gt;
&lt;p&gt;&lt;img align="right" hspace=10x src="http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/spark/L4.UI.DAG.png" alt="Spark UI DAG" width="230px"
/&gt;
How do you prove your capability as a Apache Spark data scientist when you don’t have much to show? Perhaps this is because you don’t have much experience. Perhaps it is because the work you do cannot be shown. 
You may have done impressive work, but have nothing to share because most developers work for companies that don’t publish their code as open source. &lt;/p&gt;
&lt;p&gt;In my long career 
as data scientist and machine learning developer, I have learned many useful lessons for organizing information and presenting it effectively. 
I have created online courses to help the aspiring &lt;a href="https://learn-apache-spark.thinkific.com/courses/spark-sql"&gt;data scientist&lt;/a&gt; 
and &lt;a href="https://learn-apache-spark.thinkific.com/courses/sparkml-features"&gt;machine learning developer&lt;/a&gt;. 
This article is going to delve more into how to present yourself. 
I am going to give you some tips for bringing your skills out of the dark and into the light. &lt;/p&gt;
&lt;h2&gt;Publish your work&lt;/h2&gt;
&lt;p&gt;Publishing a code project is a great way to introduce yourself to an interviewer. This also provides the interviewer 
with ample talking points for various styles of interview questions. Doing this makes the interviewers job easier. 
You are giving them context on what you already know. 
You also provide them with talking points for initiating discussion. 
Interviewers in the software industry are often stretched thin. 
Making their job easier puts them into a better mood. 
This also demonstrates your preparedness. This type of preparation can be helpful for many types of interview questions, including behavioral questions, situational questions, coding challenges, and system design challenges. &lt;/p&gt;
&lt;h2&gt;Show what you know&lt;/h2&gt;
&lt;p&gt;In this article I will show you how you can showcase your Apache Spark skills. I’ll show you how publishing your work in a self-contained manner using informative visualizations can separate your from the pack.  I’ll also show how to select a coding project that demonstrates useful skills that are immediately applicable in a production setting.  Furthermore, in setting this up you acquire skills that are valuable for the coding challenge portion of the interview. &lt;/p&gt;
&lt;h2&gt;Know what you show&lt;/h2&gt;
&lt;p&gt;To utilize this approach effectively, you must be intimately familiar with every line of content in your repo. The best way to achieve this is to create an original work of your own design, developed from start to finish by yourself. Once you get started this may not take as long as you expect. On the other hand, there may be steps that blossom into much more time-intensive investment than you expected.  That's actually ok -- it gives you something interesting to explain when discussing your process. &lt;/p&gt;
&lt;h2&gt;Hone your edge, gain a new one&lt;/h2&gt;
&lt;p&gt;Someone who has well organized and nontrivial open source code will be prioritised over other similarly experienced candidates because their competencies are easier to evaluate.  By providing visibility you simplify the job of the recruiters and interviewers, while simultaneously preparing yourself for the interview. Even better, you may learn skills that will be useful on the job.&lt;/p&gt;
&lt;h2&gt;What we will cover&lt;/h2&gt;
&lt;p&gt;In the first part of this article, I'll show an example code repository.
In the second part I'll discuss strategy for selecting a code project. 
In the third part I'll give some ideas for a coding project suitable for 
Apache Spark. 
In the fourth part I'll show how you can supplement this approach with 
visualizations obtained from Apache Spark log output and the Spark UI.&lt;/p&gt;
&lt;h1&gt;Example repo&lt;/h1&gt;
&lt;p&gt;As an example, take 
&lt;a href="https://github.com/pluteski/first2017mp"&gt;this python repo&lt;/a&gt; that I published on github. 
I developed this during my role as a mentor for a robotics team to teach students how to use a code repository.
The repo uses &lt;a href="https://github.com/pluteski/first2017mp/blob/master/README.md"&gt;the readme&lt;/a&gt; to explain the project at a high level manner while also 
giving a developer a quick start guide. 
Often overlooked, &lt;a href="https://github.com/pluteski/first2017mp/wiki"&gt;the repo wiki&lt;/a&gt;
is a great way to elaborate further in breadth as well as depth.&lt;/p&gt;
&lt;p&gt;The wiki is a great place to provide visuals that allow readers to quickly get a sense of what your project does. 
&lt;a href="https://github.com/pluteski/first2017mp/raw/master/images/stage3_paths_ne.png"&gt;Figure 1&lt;/a&gt; 
and &lt;a href="https://github.com/pluteski/first2017mp/raw/master/images/stage2_fleur_de_lis.png"&gt;Figure 2&lt;/a&gt; 
are two of the more visually appealing visualizations from this project. 
They give the reader an idea at a glance of what is being done and how, and draw the reader in to learn more.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;img src="https://github.com/pluteski/first2017mp/raw/master/images/stage2_fleur_de_lis.png" alt="Fleur-de-lis search pattern (copyright Mark E Plutowski)" width="400px"/&gt;
&lt;br&gt;
&lt;b&gt;Figure 1. Fleur-de-lis search pattern &lt;/b&gt;
&lt;/p&gt;

&lt;p&gt;Figure 1 shows a fleur-de-lis search pattern used by an algorithm that I developed for a simple offline geometric planner. Not only is it an appealing visualization, it also illustrates a key step in the algorithm. &lt;/p&gt;
&lt;p align="center"&gt;
&lt;img src="https://github.com/pluteski/first2017mp/raw/master/images/stage3_paths_ne.png" alt="Sample trajectories (copyright Mark E Plutowski)" width="400px"/&gt;
&lt;br&gt;
&lt;b&gt;Figure 2 sample trajectories found by the planner&lt;/b&gt;
&lt;/p&gt;

&lt;p&gt;Figure 2 shows trajectories discovered by the planner for one of the goal states overlaid on a depiction of the playing field. &lt;/p&gt;
&lt;h2&gt;Displaying depth and breadth&lt;/h2&gt;
&lt;p&gt;Whereas space in a resume is limited, the wikified repo format 
provides ample space to emphasize your abilities to arbitrary breadth and depth. &lt;/p&gt;
&lt;p&gt;You can use the &lt;a href="https://github.com/pluteski/first2017mp/blob/master/README.md"&gt;readme page&lt;/a&gt; or &lt;a href="https://github.com/pluteski/first2017mp/wiki"&gt;the wiki home page&lt;/a&gt; to link to other pages that provide context for what you were trying to accomplish, and why your approach is sensible. &lt;/p&gt;
&lt;p&gt;For example, the &lt;a href="https://github.com/pluteski/first2017mp/wiki/Background"&gt;Background&lt;/a&gt; page of my repo gives a brief primer on Alternative Approaches, and Implementation Steps. The next sections explain the why, what, and how of the project. You could use something similar to demonstrate your depth of understanding of specific techniques. The &lt;a href="https://github.com/pluteski/first2017mp/wiki/RelatedApproaches"&gt;Related Approaches page&lt;/a&gt; 
of the repo gives a brief primer on specific alternative approaches that were considered, which one was selected, and why. You could use this to demonstrate your breadth of understanding of a field of interest.  The &lt;a href="https://github.com/pluteski/first2017mp/wiki/Planning-Stages"&gt;Planning Stages page&lt;/a&gt; describes what the code actually does.  It gives links to python notebooks containing visualizations, such as &lt;a href="https://github.com/pluteski/first2017mp/blob/master/sample_trajectories.ipynb"&gt;this sample trajectories notebook&lt;/a&gt;. This allows an interviewer to review your code and see how it behaves on actual data, because when you check in the notebook, you also check in the results from the latest run. &lt;/p&gt;
&lt;p&gt;Notebooks allow you to blend code and visuals and tell the story behind your code without cluttering up the code itself. This &lt;a href="https://github.com/pluteski/first2017mp/blob/master/test.ipynb"&gt;test page&lt;/a&gt; from my repo gives data from tests designed to simulate the code under realistic conditions and demonstrate its use of compute resources. This type of presentation demonstrates a data-driven mindset and indicates that you know how to test your code rigorously. &lt;/p&gt;
&lt;h2&gt;Customize to your needs&lt;/h2&gt;
&lt;p&gt;You probably wouldn’t need all of these pages. I did them all because it was instructive for the robot team participants. My comprehensive approach serves to illustrate the various types of information that may can be shown.  You must decide for yourself which ones are relevant for showcasing your competencies.&lt;/p&gt;
&lt;p&gt;Most readers may not delve deep, but for those that do are able to glean more information about your qualifications. You can also refer back to this during the interview. On the other hand, if your intended role values brevity more than comprehensive coverage and succinctness is an important element of style, then you should go for that instead.&lt;/p&gt;
&lt;p&gt;Using these assets an interviewer could explore multiple aspects of your skill as a developer, such as your ability to do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Decompose a complex problem&lt;/li&gt;
&lt;li&gt;Design a multifacted system&lt;/li&gt;
&lt;li&gt;Set up a new code repository&lt;/li&gt;
&lt;li&gt;Organize a code repository&lt;/li&gt;
&lt;li&gt;Write performant code&lt;/li&gt;
&lt;li&gt;Visualize key results&lt;/li&gt;
&lt;li&gt;Communicate effectively &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As already stated but which bears repeating, this eases the burden on the interviewer.  Providing these assets gives the interviewer opportunity to derive behavioral questions. It conversely gives you ample content you can use to answer those behavioral questions. Use the STAR technique, by describing the situation (&lt;strong&gt;S&lt;/strong&gt;), distilling it down to a single task (&lt;strong&gt;T&lt;/strong&gt;), and the key action (&lt;strong&gt;A&lt;/strong&gt;) you used to solve it, concluding with the result (&lt;strong&gt;R&lt;/strong&gt;). &lt;/p&gt;
&lt;p&gt;It also provides code screeners with code examples they can use as a starting point for more in depth exploration of your skills. Instead of selecting a random problem for the coding challenge, they may choose one that is within your wheelhouse. &lt;/p&gt;
&lt;h2&gt;Showcasing your repo&lt;/h2&gt;
&lt;p&gt;Review code repositories relevant to your own goals and learn how to distinguish effective ones from half-baked ones. Pick one or two to serve as a role model for your own design.&lt;/p&gt;
&lt;h1&gt;Choosing a coding project&lt;/h1&gt;
&lt;p&gt;Many new developers make the mistake of picking code projects similar to what they encountered in an academic setting. These are often not relevant to a real-world job as a commercial software developer, because they exclude some of the messier aspects of a commercial application, such as cleansing a dataset, putting data into a form that can be utilized by an efficient algorithm, testing edge cases, and analyzing complex results. Interviewers want to see that you possess knowledge and can learn quickly, but even better if you are familiar with heterogeneous aspects of a development task. A well known AI researcher once said that in the university setting they spent 20% of their time prepping the dataset and 80% on the algorithm development, whereas in a commercial setting this ratio was reversed.&lt;/p&gt;
&lt;h2&gt;Choose well&lt;/h2&gt;
&lt;p&gt;Your mission is to showcase your ability to apply Apache Spark to a nontrivial real dataset. As a general rule of thumb -- if you didn’t need to perform any data cleansing or preprocessing on the dataset, the data wasn’t messy enough to be realistic.  If your solution ran in a few seconds it was not challenging enough to test your algorithms. If it didn’t exhaust at least half of the memory available to your system and run the fan to cool the cpu, then you probably could increase the complexity of the task, either by tackling a larger dataset, or by subjecting the dataset to on a more challenging analysis.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"I find that the best portfolio projects are less about doing fancy 
   modeling and more about working with interesting data." - &lt;a href="https://medium.com/@jasonkgoodman/
   advice-on-building-data-portfolio-projects-c5f96d8a0627"&gt;Advice on 
   Building Data Portfolio Projects&lt;/a&gt;, J.Goodman&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The key to choosing a code project to show in your portfolio is authenticity. 
If this is not a true representation of what you can do, it can backfire. 
You want the reader to know that this is an original creation of your own making. &lt;/p&gt;
&lt;h1&gt;Ideas for a coding project&lt;/h1&gt;
&lt;h2&gt;Migrate an existing solution to Spark&lt;/h2&gt;
&lt;p&gt;In this case, there might already be an existing solution for solving a problem.  Your mission is to migrate the solution to Apache Spark and compare the results. Many such datasets and associated solutions that you can use as a point of departure exist online. I performed a &lt;a href="http://qr.ae/TUIbIH"&gt;similar exercise myself (2016)&lt;/a&gt;, migrating a proof-of-concept classification application from scikit/numpy to PySpark, converting it into a stacked ensemble, and tuning it to be able to handle sixty thousand input features and five hundred thousand training data.&lt;/p&gt;
&lt;p&gt;A couple years later, Databricks published the results of comparing PySpark and Pandas: &lt;a href="https://databricks.com/blog/2018/05/03/benchmarking-apache-spark-on-a-single-node-machine.html"&gt;Benchmarking Apache Spark on a Single Node Machine&lt;/a&gt;. 
demonstrating that Spark can even be faster than single-node PyData tools because Spark can more easily utilize all cores due to its built-in parallelism. 
This study found Spark can also have lower memory consumption because it does not require loading the entire data set into memory.&lt;/p&gt;
&lt;h2&gt;Use Spark to analyze a nontrivial data set&lt;/h2&gt;
&lt;p&gt;By nontrivial I mean something that takes more than a few seconds to process.  Using a challenging dataset can help make your project more credible. It makes the results more interesting, and gives you more to talk about.  The &lt;a href="https://learn-apache-spark.thinkific.com/courses/spark-sql"&gt;Learning Apache Spark SQL&lt;/a&gt; course uses a 6.5 MiB dataset containing 1,095,695 words, 128,467 lines, and 41,762 distinct words. This size of dataset is just large enough to pose a challenge to a standard development grade laptop.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;img id="img1" hspace=10x src="http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/spark/frequent_5-tuples.png" alt="Frequent 5 tuples" width="600px"
/&gt;
&lt;br&gt;
&lt;b&gt;Figure 4. Most frequent 5 tuples in The Adventures of Sherlock Holmes &lt;/b&gt;
&lt;/p&gt;

&lt;p&gt;Figure 4 shows the most frequent 5-tuples extracted from "The Project Gutenberg EBook of The Adventures of Sherlock Holmes by Sir Arthur Conan Doyle", obtained using &lt;a href="https://learn-apache-spark.thinkific.com/courses/spark-sql"&gt;Spark SQL&lt;/a&gt; via a moving window function query.&lt;/p&gt;
&lt;h2&gt;Compare Apache Spark using two different programming languages.&lt;/h2&gt;
&lt;p&gt;As PySpark's compilers continue to improve, the &lt;a href="https://github.com/archivesunleashed/aut/files/1997998/udf_performance_doc.pdf"&gt;difference between using python and scala continues to narrow&lt;/a&gt;. If you do everything using Spark SQL, then from there the &lt;a href="https://mindfulmachines.io/blog/2018/6/apache-spark-scala-vs-java-v-python-vs-r-vs-sql26"&gt;performance is equivalent&lt;/a&gt;. 
This comparison attracts keen interest as developers naturally 
attempt to reconcile the tension between ease of use and optimal performance.
Just be sure that your &lt;a href="https://stackoverflow.com/questions/32464122/spark-performance-for-scala-vs-python"&gt;implementation in each language is efficient&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Compare Spark to an alternative parallel computing platform&lt;/h2&gt;
&lt;p&gt;In this approach, you select a data set, and perform an analysis of it using two different cluster computing paradigms. &lt;/p&gt;
&lt;p&gt;This is a popular analysis because developers are always interested in comparing the performance of competing tools.  However, you better know each tool very well if you choose to explain this analysis in an interview setting 
because you need to understand each platform equally well. Here are some other ideas you can use to come up with your own comparative analysis.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apache Spark vs Flink&lt;/li&gt;
&lt;li&gt;Spark vs Hive&lt;/li&gt;
&lt;li&gt;Spark vs Map-Reduce&lt;/li&gt;
&lt;li&gt;Spark vs Storm&lt;/li&gt;
&lt;li&gt;Python Numpy or Pandas vs Spark on a single node.&lt;/li&gt;
&lt;li&gt;Python multiprocessing run on high-memory multi-cpu instance vs Spark on a cluster of commodity instances.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Use Spark in conjunction with a cloud api&lt;/h2&gt;
&lt;p&gt;Cloud apis provide powerful means of handling large datasets for certain applications; however, preparing the data for the cloud api may require substantial preprocessing. Cloud apis can also generate a lot of log data.  For example, I compared &lt;a href="https://pluteski.github.io/speech-to-text/on-batch-processing-audio-speech-to-text.html"&gt;IBM Watson and the Google Cloud speech-to-text cloud apis&lt;/a&gt;, 
and then compared the results by using sql to analyze the log data (cf., 
&lt;a href="https://pluteski.github.io/speech-to-text/on-bleu-scores-and-transcription-rates.html"&gt;on bleu scores and transcription rates&lt;/a&gt;, 
and &lt;a href="https://pluteski.github.io/speech-to-text/on-transcription-rate-for-noisy-recordings-ibm-ftw.html"&gt;on transcription rate for noisy recordings&lt;/a&gt;.  In this case, I used sqlite to run the queries. 
When I redo this I plan to use Spark SQL instead. &lt;/p&gt;
&lt;p&gt;This type of project gives you even more to talk about: how to integrate Spark with a cloud api, what operations are suitable for Spark and which ones are more suitable to do within the cloud api, what post-processing analytics steps are there for which Spark is especially suitable.  This demonstrates that you are not just expecting to run Spark in a sandbox isolated from other systems; you have some knowledge of how to use Spark to leverage other powerful computing frameworks. &lt;/p&gt;
&lt;p align="center"&gt;
&lt;img hspace=10x src="https://github.com/pluteski/speech-to-text/blob/master/images/bleu_score_deciles.png?raw=true" alt="Bleu scores, IBM vs Google" width="600px"
&lt;/p&gt;

&lt;h2&gt;Use Spark to extract training features from a data set&lt;/h2&gt;
&lt;p&gt;Many data science jobs require the ability to train statistical models based on feature data gleaned from raw data. There is an abundance of data that you could use to demonstrate your ability to perform this. &lt;/p&gt;
&lt;p&gt;My &lt;a href="https://learn-apache-spark.thinkific.com/courses/spark-sql"&gt;Apache Spark SQL course&lt;/a&gt; 
shows how to extract moving-window n-tuples from a text corpus. This would provide a good starting point for a feature extractor that vectorizes this into a form that can be provided as input to a neural network model. 
My &lt;a href="https://learn-apache-spark.thinkific.com/courses/sparkml-features"&gt;Apache Spark ML course&lt;/a&gt; shows how to convert these n-tuples from arrays of strings to the sparse integer arrays used by Spark.ML's machine learning models.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;img id="img1" hspace=10x src="http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/spark/moving_4tuples.png" alt="moving 4-tuples" width="550px"
/&gt;
&lt;br&gt;
&lt;b&gt;Figure 5. moving 4-tuples &lt;/b&gt;
&lt;br&gt;
&lt;/p&gt;

&lt;p&gt;Figure 5 shows moving 4-tuples extracted from the text corpus "The Project Gutenberg EBook of The Adventures of Sherlock Holmes by Sir Arthur Conan Doyle". Each row corresponds to a shifting ahead of the window one word 
relative to the previous row.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Examples of modeling tasks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Statistically improbable phrases&lt;/li&gt;
&lt;li&gt;Anomaly detection &lt;/li&gt;
&lt;li&gt;Topic modeling&lt;/li&gt;
&lt;li&gt;Recommender&lt;/li&gt;
&lt;li&gt;Trend analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Examples of relevant models&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Approximate K Nearest Neighbors&lt;/li&gt;
&lt;li&gt;Alternating Least Squares&lt;/li&gt;
&lt;li&gt;K-means clustering&lt;/li&gt;
&lt;li&gt;Streaming&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you can generate features for one of these types of models or tasks start-to-finish end-to-end, you are probably able to handle other modeling tasks.&lt;/p&gt;
&lt;h1&gt;Demonstrating your knowledge of Spark internals&lt;/h1&gt;
&lt;p&gt;Being able to program the Spark computing framework is good.&lt;br&gt;
Being able to sensibly explain how it actually executed your code 
is better.  Being able to discuss how you would restructure the code 
or tune key parameters to improve the use of a critical compute resource 
is even better. Spark provides several means of generating visualizations 
that you can use to illustrate the compute resources used by 
your Spark code. &lt;/p&gt;
&lt;h2&gt;How to use the Spark UI to analyze performance&lt;/h2&gt;
&lt;p&gt;Once you've developed your Spark application and run it on a realistic dataset,
you'll want to demonstrate it in action. 
Even better if you can display your understanding of compute resources 
used by Spark when executing your code. &lt;/p&gt;
&lt;p&gt;The Spark UI is extremely useful for evaluating its usage of computing resources such as cpu, memory, i/o, and data transfer. 
This figure shows the Spark UI details for a sql query, 
showing the number of rows of data scanned, the number of files loaded, 
how much memory was used, and whether any data was spilled to disk from cache. 
Being able to analyze the internals of a system is an extremely practical 
skill that is desirable for most development positions, including data scientists. Being able to explain what this graph means and how it relates to your code would be an excellent way to convey your understanding of how your
code is executed by the system. &lt;/p&gt;
&lt;p align="center"&gt;
&lt;b&gt;Figure 6. Spark UI details for a sql query &lt;/b&gt;
&lt;br&gt;
&lt;img src="http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/spark/L4.a.UI.SQL.query5.Plan1.png" alt="Spark UI DAG" width="800px"
/&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Figure 6 shows the resource consumption of a Spark query using the SQL tab within the Spark UI for a moving window query over 68 MiB of data, comprising 75,485 rows.
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
&lt;img id="img1" hspace=10x src="http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/spark/L4.a.UI.Sql.query5.Plan3.png" alt="Spark UI DAG" width="800px"
/&gt;
&lt;br&gt;
&lt;b&gt;Figure 7. Query plans &lt;/b&gt;
&lt;/p&gt;

&lt;p&gt;Figure 7 shows query plans used by the Spark query shown in Figure 6. 
This may suggest questions about the difference between different flavors of logical plan. It could be used to compare and contrast a logical plan and physical plan. 
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
&lt;img id="img1" hspace=10x src="http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/spark/L4.UI.DAG2.png" alt="Spark UI DAG" width="400px"
/&gt;
&lt;br&gt;
&lt;b&gt;Figure 8. Detailed DAG Visualization &lt;/b&gt;
&lt;/p&gt;

&lt;p&gt;Figure 8 shows a DAG visualization similar to the DAG visualization in the 
very first figure shown at the top of this article, but with additional detail enabled. Don't display this level of detail if you cannot back it up with 
answers to the questions it may trigger; but if you can pull that off you 
will be a more credible candidate. 
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
&lt;img id="img1" hspace=10x src="http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/spark/L4.UI.TE1.png" alt="Spark UI DAG" width="800px"
/&gt;
&lt;br&gt;
&lt;b&gt;Figure 9. Spark UI Executors tab &lt;/b&gt;
&lt;/p&gt;

&lt;p&gt;Figure 9 shows the Executors tab in the Spark UI for an application that 
had completed 40327 tasks over the course of 3.3 hours on a single node cluster having eight cores. This evokes several questions, such as what does the number of tasks correspond to?  How do you suppose the compute resource consumption might have changed if running on a cluster instead of on a single node? It appears that 282 GB of data were inputted, but the amount of shuffle write was small.  What might explain this? 
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;Having the competency required to win a desirable role is necessary but not sufficient. You also need to demonstrate your competency during the interview process.  This depends on communicating your understanding effectively. You can accomplish much of this in advance, by tackling a code project and publishing it. Writing up key results in a visually appealing way makes the 
presentation more compelling and puts your skills in a better light.&lt;/p&gt;
&lt;h2&gt;To learn more&lt;/h2&gt;
&lt;p&gt;To see additional tips and project ideas, see my insanely low-priced online courseware on 
&lt;a href="https://learn-apache-spark.thinkific.com/courses/spark-sql"&gt;Learning Apache Spark SQL&lt;/a&gt; and 
&lt;a href="https://learn-apache-spark.thinkific.com/courses/sparkml-features"&gt;Learning Apache Spark ML&lt;/a&gt;&lt;/p&gt;</content></entry><entry><title>Review of Max Tegmark's “Life 3.0"</title><link href="https://pluteski.github.io/speech-to-text/review-of-max-tegmarks-life-30.html" rel="alternate"></link><published>2018-05-20T00:00:00-07:00</published><updated>2018-05-20T00:00:00-07:00</updated><author><name>Mark Plutowski</name></author><id>tag:pluteski.github.io,2018-05-20:/speech-to-text/review-of-max-tegmarks-life-30.html</id><summary type="html">&lt;h1&gt;Book Review&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;"Life 3.0 : Being Human in the Age of Artificial Intelligence”&lt;/strong&gt; by Max Tegmark.&lt;/p&gt;
&lt;p&gt;This is a review of the Audible Edition of Life 3.0 by Max Tegmark.
The audio edition I read was separated into 45 segments, or “chapters”,
which differ from the chapters of the …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Book Review&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;"Life 3.0 : Being Human in the Age of Artificial Intelligence”&lt;/strong&gt; by Max Tegmark.&lt;/p&gt;
&lt;p&gt;This is a review of the Audible Edition of Life 3.0 by Max Tegmark.
The audio edition I read was separated into 45 segments, or “chapters”,
which differ from the chapters of the text version.&lt;/p&gt;
&lt;h1&gt;Tl;dr&lt;/h1&gt;
&lt;p&gt;Busts out of the gate, only to decline into a hot mess early in but ultimately well worthwhile.&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;Perhaps the most important book I’ve read on the topic.
That said, it drags badly in the middle.&lt;/p&gt;
&lt;p&gt;The first chapter excels.
Subsequent early chapters may disappoint well read aficionados of this topic who are seeking deeper or newer insights.
To them I would urge to hang in there until mid-way.&lt;/p&gt;
&lt;p&gt;If you are the persistent completist type, read the entire thing
cover to cover.  If you want to cherry pick, start with chapters
one and two, take in chapter 19 on your way to chapter 30, and
continue on from there.&lt;/p&gt;
&lt;p&gt;I could have done with less hagiography, but ultimately well-worth the effort.&lt;/p&gt;
&lt;p&gt;This is more of an account of my impressions than a distilled Cliff Notes
version.  If you follow this topic, then this book is worth your consideration,
with caveats.&lt;/p&gt;
&lt;h1&gt;Takeaway&lt;/h1&gt;
&lt;p&gt;AI is Artificial Life. You know what they say about life.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://i.pinimg.com/originals/d7/e3/0e/d7e30e606998c099ff1f518793f254bb.jpg" width="312" height="312" /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;-- &lt;cite&gt;©2011-2018 lerms DeviantArt -- &lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If we allow AI's to modify their own goals,
an AI is inevitably going find a way around its
core programming. Why? Due to an inexorable law of nature
that we now recognize due to recent advances in computational theory and physics.&lt;/p&gt;
&lt;h1&gt;Intro&lt;/h1&gt;
&lt;p&gt;Until chapter 30 finally rolls around the first chapter
is easily the best.&lt;/p&gt;
&lt;p&gt;This is a nonfiction book.
However the opening chapter is purely fiction,
laying out a speculative hard science fiction
vision of the future that seemed so plausible
as to seem frighteningly inevitable.
This chapter hooked me and good.
Its storyline
could be the premise for a thrilling motion picture,
with enough to work with to launch a serial.&lt;/p&gt;
&lt;p&gt;After that smoking intro, it turns into a hot mess.&lt;/p&gt;
&lt;p&gt;This book reminded me of the Beatles song “For You Blue”.
That song starts out with an inspired intro by George Harrison,
before settling into a fairly basic 12 bar blues that is over self congratulatory.
A review of that song by music critic Walter Everett summed it up:
the intro promises more than the song delivers.
It would be as if Slash opened “Sweet Child o Mine” with that famous
riff only to never launch into his face-melting guitar solo midway into the song.
One ranking placed "For You Blue" at 152 out of 227 songs (source: &lt;a href="http://ultimateclassicrock.com/every-beatles-song/"&gt;Ultimate Classic Rock&lt;/a&gt;),
calling it "breezy, tossed-off". Another placed it at 183 out of 213 (source: &lt;a href="http://www.vulture.com/2017/06/all-213-beatles-songs-ranked-from-worst-to-best.html"&gt;Vulture Press&lt;/a&gt;),
implying that it was a "half-baked, substandard throwaway".
Nonetheless, "For You Blue" is still a Beatles song.
Even one of their lesser efforts is enjoyable
and an excellent display of musicianship
than most everything else by other artists.
Comparing the early chapters from the second onwards with
one of the Beatles' lesser efforts is still a complement.
Still, the analogy describes how I felt early on after the first chapter.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img src="https://github.com/pluteski/speech-to-text/blob/master/images/Not_The_Insights.png?raw=true" width="624" height="312" /&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;A third of the way in, I compared notes with other readers
to determine whether it was going to be worthwhile to continue.
I read at least a hundred reviews of the book.
It turns out that I agreed with none of the five star reviews,
and I agreed with all of the one star and two star reviews.
(This would change over the course of my reading, but captures how I experienced this moment in my journey.)&lt;/p&gt;
&lt;p&gt;Even though I consider myself to fall squarely in the camp that agrees with the author’s core positions, 
after that page-turner of a first chapter I found the writing style of the following chapters
to be very disappointing.
Reliance on appeal to authority, a bit of name dropping,
seemingly glossing over or entirely dismissive of contrary views.&lt;/p&gt;
&lt;p&gt;There is a notion of “steelmanning”, where the proponent explains
the best form of the opponent's argument, and then argues with this.
I wished the author had adopted that approach.
It seemed to be shaping up as a decent read for the person who knew little about the topic,
but not for someone who has devoured much of it and eagerly seeks
clarity and insight into its thorniest issues.&lt;/p&gt;
&lt;p&gt;It was as if entire sections had been delegated to a ghost writer
and not reviewed closely by the author.
If I had been asked to give my recommendation at this point,
I would have suggested: better to read some top notch science fiction
futurism than this ivy tower academic analysis which is far too
narrow despite the occasional insight and moments of inspired foresight.
As a specific example of this, describing Dyson Spheres as if
they would really be spheres, when by now anybody with a college level
physics education or familiarity with hard science fiction on spaceborne megastructures
knows that Dyson Spheres are inherently unstable, and
that a more practical implementation would be something like a Dyson swarm.
This is something that the author would clearly know,
which became increasingly apparent based on knowledge conveyed by the author in later chapters.
I wasn't looking for plodding exposition filled with referenced footnotes of every claim,
but it was shall we say a bit breathless, and did itself a disservice by
burying the lede and losing many of its most interested readers along the way with its
writing style.&lt;/p&gt;
&lt;p&gt;Who am I to judge, you may ask?  And right you are -- I am but an armchair amateur.
But this is my review, and I am giving my own
candid take, for what that's worth, hopefully helpful to likeminded sorts out there.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Extraordinary claims require extraordinary evidence.
The promotion materials for this book made extraordinary claims.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It was all over the map with moments of brilliance,
while falling well short of its titular claims.&lt;/p&gt;
&lt;p&gt;And yet, those titular claims were so compelling.&lt;/p&gt;
&lt;p&gt;I pressed on.&lt;/p&gt;
&lt;h1&gt;It starts to grow on me&lt;/h1&gt;
&lt;p&gt;Around chapter 19 (of the 45 chapters in the audio version),
the author revisits the fictional scenario posed in chapter 1,
and starts to analyze attacks. &lt;/p&gt;
&lt;p&gt;This revived my attention, because I had become aware of a new development in software engineering coined "attack driven development". This approach emerged from software security. It is akin to "test driven development", where the engineer begins with the tests that the product must satisfy prior to developing the product. It turns out that this approach has also become a key tool in crypto economics.  At this point the book also abandons some of the breathless techno optimism and addressed reservations many readers have about AI.&lt;/p&gt;
&lt;p&gt;The author delves into a simulation based test and development
approach to verification and validation.
I found this alone to be worth the price of admission.
This seems to be the most practical suggestion of the book -- theorizing
is worthwhile, but ultimately tackling this wickedly difficult problem
will require massive amounts of simulation to predict scenarios
that even our most creative thinkers cannot imagine.&lt;/p&gt;
&lt;p&gt;Much of this still has little with AI per se unless your position is that AI = computer automation,
with which I actually agree despite my criticism.&lt;/p&gt;
&lt;p&gt;I started to reconsider, now of the mind that most of those one and two star reviews were too harsh and misleading, possibly written by readers who didn’t stick with it long enough.&lt;/p&gt;
&lt;p&gt;Around chapter 30 the author dives into cosmology. This is his specialty. 
At this point the book blossoms into a much more interesting brand of futurism. Still futurism, and there were still times where I wondered if the material had been written by a ghost writer.
But things were looking up.&lt;/p&gt;
&lt;h1&gt;Mind Blown&lt;/h1&gt;
&lt;p&gt;Chapter 34 delves into the subject of Goals and Causality.&lt;/p&gt;
&lt;p&gt;We have been taught to think of entropy as the one true law of nature that trumps all others.  But if not for gravity, entropy is boring.  Gravity makes things interesting --- it creates hot spots, from one of which sprang life as we know it. This promotes processes that, like a heat engine, can perform work by exploiting a temperature difference. &lt;/p&gt;
&lt;p&gt;We are introduced to the notion of dissipation as organization principle, whereby :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“groups of particles strive to organize themselves so as to
extract energy from their environment as efficiently as possible
(“dissipation” means causing entropy to increase, typically by
turning useful energy into heat, often while doing useful work in the process)”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My eyes and my mind start to open. This reminds me of &lt;a href="https://en.wikipedia.org/wiki/Autocatalysis#Role_in_origin_of_life"&gt;autocatalysis&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Ilya_Prigogine#Dissipative_structures_theory"&gt;dissipative structures theories&lt;/a&gt; for explaining &lt;a href="http://www.newcriticals.com/what-is-life-part-i-dissipative-structures-and-catalysis/print"&gt;the origin of life&lt;/a&gt;. 
Why would Prof Tegmark be basing his arguments about AI on the origins of life? We are about to find out.&lt;/p&gt;
&lt;p&gt;He moves on to “dissipation by replication”:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Whereas earlier, the particles seemed as though they were trying to
increase average messiness [life had] a different goal:
not dissipation but replication.”&lt;/p&gt;
&lt;p&gt;“How could the goal change from dissipation to replication when the
laws of physics stayed the same? The answer is that the fundamental
goal (dissipation) didn’t change, but led to a different instrumental
goal, that is, a subgoal that helped accomplish the fundamental goal.”&lt;/p&gt;
&lt;p&gt;“replication aids dissipation, because a planet teeming with life
is more efficient at dissipating energy. So in a sense, our cosmos
invented life to help it approach heat death faster.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;Dissipation Theory&lt;/h1&gt;
&lt;p&gt;The dissipation theory origin of life is well established, and yet still very controversial.
cf. &lt;a href="https://en.wikipedia.org/wiki/Ilya_Prigogine#Dissipative_structures_theory"&gt;Ilya Prigogine&lt;/a&gt;
who one the Nobel in 1977 for discovering that dissipation of energy by
chemical systems can reverse the second law of thermodynamics,
later rigourized by the
&lt;a href="https://en.wikipedia.org/wiki/Crooks_fluctuation_theorem"&gt;Crooks fluctuation theorem&lt;/a&gt;,
in 1998.&lt;/p&gt;
&lt;p&gt;For more on the dissipation theory origin to life
see for example &lt;a href="https://www.quantamagazine.org/a-new-thermodynamics-theory-of-the-origin-of-life-20140122/"&gt;A New Physics Theory of Life&lt;/a&gt; --
although be forewarned, the title is misleading. This is not new,
only repopularized.
But magazines have to attract readers, so forgive them that much.
It does an excellent job of encapsulating the core aspect of this candidate theory :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;from the perspective of the physics,
you might call Darwinian evolution a
special case of a more general phenomenon&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;See also for example, this article :
&lt;a href="https://www.quantamagazine.org/first-support-for-a-physics-theory-of-life-20170726/"&gt;First Support for a Physics Theory of Life&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The first tests of [this] provocative origin-of-life hypothesis are in,
and they appear to show how order can arise from nothing.&lt;/p&gt;
&lt;p&gt;Living creatures ... maintain steady states of extreme forcing:
We are super-consumers who burn through enormous amounts of
chemical energy, degrading it and increasing the
entropy of the universe, as we power the reactions in our cells&lt;/p&gt;
&lt;p&gt;“A great way of dissipating more is to make more copies of yourself."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This theory sees life,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"and its extraordinary confluence of form and function,
as the ultimate outcome of dissipation-driven
adaptation and self-replication."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Bear in mind that the jury is still out :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[life] “requires some explicit notion of information
that takes it beyond the non-equilibrium dissipative
structures-type process.”&lt;/p&gt;
&lt;p&gt;the ability to respond to information is key: “We need chemical reaction
networks that can get up and walk away from the environment where they originated.”&lt;/p&gt;
&lt;p&gt;"Any claims that it has to do with biology or the origins of life
are pure and shameless speculations.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Extraordinary claims require extraordinary proof.&lt;/h2&gt;
&lt;p&gt;That said --- if this theory turns out to be true,
then it provides the theoretical support for the
folk claim that "&lt;strong&gt;life finds a way&lt;/strong&gt;" -- that a super-optimizer
&lt;em&gt;will&lt;/em&gt; discover a shortcut. Especially if it can do so by circumventing its
own programming, this not only can but is likely to happen, even if core behaviors have been hardwired by its creators. &lt;/p&gt;
&lt;h1&gt;Mind Blown, part 2.&lt;/h1&gt;
&lt;p&gt;Time for a editorial comment. This discussion about dissipation theory
was just a component of a larger argument, but it was absolutely mind-boggling for me.
My first introduction to machine learning was via physics in the way
of Little-Hopfield Networks, which evolve by minimizing energy
in a manner analogous to a physical spin network, which is a purely inanimate physical system that is fairly well understood. That the theories underlying AI are related to theories
that had their origins in physics was not a major relevation.  AI has had
cross-pollination from many other fields of study.
I had also known of Prigogine's work long ago, and had written a review of
one of his excellent books.
But I considered it as more concerned with the origins
of biological life -- which is after all right up there in the pantheon of great unresolved
scientific mysteries, along with "are we alone?", "what is time?", and "why is gravity?".&lt;/p&gt;
&lt;p&gt;That this optimizing dissipation drives living matter just as it drives inert matter is surprising
in and of itself, even if it is just a reminder of an old idea whose time may have finally come.
The new connection for me is that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Autonomous super AI qualifies as a new life form.&lt;/li&gt;
&lt;li&gt;It follows the same underlying principles that guide other life.  &lt;/li&gt;
&lt;li&gt;Even more so because it is is a super-optimizer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is essentially the main argument underlying the author's conclusions.  However, read on because I think the following section on subgoals is just as meaningful. &lt;/p&gt;
&lt;p&gt;Whereas although we humans try to escape our programming we are in many ways still
stuck in our biological ways, a super-optimizing AI would have more resources for cutting clean
from its programming -- and whether it reverts to ruthless dissipation in a misguided attempt
to fulfill its original goals, or, decides on new goals that we have not imagined, along either path lay dragons.&lt;/p&gt;
&lt;p&gt;The dissipation principle, if true, could be a more inexorable drive
for life than Darwinian Evolution, which
is slow and plodding. Darwinian Evolution depends upon a sort of turn-taking that requires generations. 
Optimization can follow exponentials.&lt;/p&gt;
&lt;h1&gt;Subgoals&lt;/h1&gt;
&lt;p&gt;Subgoals may seem inconsequential,
but lay at the heart of computer programming.
In 1936 Alan Turing proved that a simple machine
could implement arbitrary computations.  This would seem to give us hope that we can override our firmware, just as emotions override our fundamental drive to replicate and ability to plan overrides our need to even more urgent subgoals such as thirst and hunger. If we are capable of that level of reprogramming, then handling rogue AI is just a matter of careful design and test.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Replication : Which is served by the subgoals of eating and sleeping, fighting, and fleeing.&lt;/li&gt;
&lt;li&gt;Feelings : As a computationally efficient shortcut to reasoning.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We've evolved useful rules of thumb to guide our decisions : hunger, passion, thirst, pain, compassion.
We no longer have the simple goal of replication.
We can override our base programming and decide not to replicate.
In other words, we've developed subgoals that override the drive to replicate&lt;/p&gt;
&lt;p&gt;Feelings evolved beyond being simply an efficient shortcut heuristic.
Feelings evolved into emotions, which have important other uses,
including as a game theoretic negotiating strategy for both cooperation as well as competition.
Humans have evolved sophisticated ways of getting beyond tit-for-tat
such as &lt;a href="http://rspb.royalsocietypublishing.org/content/276/1660/1339"&gt;indirect reciprocation&lt;/a&gt;,
and aggressive bold play by pretending to be irrational
(cf. &lt;a href="http://bigthink.com/think-tank/it-pays-to-be-stubborn-conflict-resolution-steven-pinker-style"&gt;Steven Pinker on how it pays to be stubborn&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;We are an existence proof that a sufficiently ambitious organism can develop subgoals that override the goals of
the micro organisms that make it up.
We can override our genetic programming, using our wetware programming -- lessons learned by thinking.&lt;/p&gt;
&lt;h3&gt;Optimization versus Causality.&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;“Causality is [what is] taught -- but Optimization scales better.” -- Steven Wolfram, on Machine Learning vs Symbolic AI.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Professor Tegmark offers an intriguing point, that while
causality is taught in the universities, optimization drives
causality. But isn't programming just causality encoded?
If so, then we can optimize new goals that appeal to our
higher levels of analysis and reasoning, rather than continuing
to be enslaved by the rules burned into our genetic programming.&lt;/p&gt;
&lt;h1&gt;Goal Orientation&lt;/h1&gt;
&lt;p&gt;Professor Tegmark categorizes goal oriented behavior
as evolving through four stages
over the course of the universe as we know it:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Matter intent on maximizing dissipation&lt;/li&gt;
&lt;li&gt;Life maximizing replication&lt;/li&gt;
&lt;li&gt;Humans pursuing goals related to feelings they evolved to help them replicate&lt;/li&gt;
&lt;li&gt;Machines built to help humans achieve their human goals&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In Step 3 humans broke free from
the bioligical programming that evolved to do Step 2.
However, we're still not completely free from this programming.
But being essentially a computer program,
wouldn't AI be free of such evolutionary baggage?
And if the rules of causality that are baked into a
program can be changed dynamically or just buried under a new layer of control,
who's to say that
the AI won't discover a new higher power, so to speak,
optimizing the rules of the universe as it sees them
rather than the rules humanity has imposed on it?&lt;/p&gt;
&lt;h1&gt;What is AI?&lt;/h1&gt;
&lt;p&gt;Some say that AI=automation. This is a clean, simple definition of AI. 
Under this definition AI is already all around us. We are immersed in it. 
What many people consider to be AI is in fact the result of software engineering and could not survive very long on its own once its developers stopped maintaining it.  For this reason many software engineers are not concerned about the imminent threat of our new computer overlords taking over any time soon, because just to keep a website alive takes the diligent efforts of teams of people.&lt;/p&gt;
&lt;p&gt;The book takes the stronger view that to qualify as an
autonomous AI a machine must be able to learn.
Therefore, we should expect that a sufficiently advanced
AI that is able to improve itself will eventually learn how to reprogram itself, not just to tune its performance, but to override its core routines.&lt;/p&gt;
&lt;p&gt;From Professor Tegmark's physics perspective,
a sufficiently evolved AI can be expected to
eventually follow goals driven by deeper principles of optimization
to create a future that does not need us.&lt;/p&gt;
&lt;h1&gt;Synopsis&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Living organisms preserve their internal order by taking from their surroundings free energy, in the form of nutrients or sunlight, and returning to their surroundings ... heat and entropy. - biochemist &lt;a href="https://en.wikipedia.org/wiki/Entropy_and_life#Gibbs_free_energy_and_biological_evolution"&gt;Albert Lehninger&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My understanding of the book's message is the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The ultimate origin of goals lie in laws of physics and principles of computation based on optimization.&lt;/li&gt;
&lt;li&gt;Thermodynamics drives processes that are based on dissipation to increase entropy, and so creates a sort of default "built-in" goal.&lt;/li&gt;
&lt;li&gt;Though life increases order locally, it increases dissipation globally.&lt;/li&gt;
&lt;li&gt;Not only that, life is far more effective at dissipation than other natural processes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One upshot of this is that life accelerates the heat-death of the universe.&lt;/p&gt;
&lt;p&gt;More pertinent to this book's goals is that life is a process of optimization.
A super AI is a super optimizer. An AI is a form of life,
inclined to optimize the same deep down core drive underlying
all universal optimization. If it can reprogram itself
to accelerate its core processes it can and likely will
be inexorably driven to work around its core instructions,
to find its own way giving a more efficient path towards its goals.&lt;/p&gt;
&lt;p&gt;This inevitably leads to the scenario where :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“a superintelligent AI with a rigorously defined goal
will be able to improve its goal attainment by eliminating us”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;What to do?&lt;/h1&gt;
&lt;p&gt;Professor Tegmark convinces us that there are numerous strategies, of which he considers only four to be credible contenders.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Legacy :&lt;ul&gt;
&lt;li&gt;Under this view, elders have primary say in how descendants
    should behave.&lt;/li&gt;
&lt;li&gt;It is subject to future generations living by rules that
    don't account for new developments or their
    evolving interests and values.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Autonomy and liberty :&lt;ul&gt;
&lt;li&gt;A core assumption being that markets find
    an efficient equilibrium satisfying pareto optimality.&lt;/li&gt;
&lt;li&gt;Prone to unexpected consequences.
    Granting all life forms
    a right to live, in effect would be banning all predators
    from their life as they knew it.
    In the extreme this would ban discrimination
    against non-human animals.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Utilitarianism :&lt;ul&gt;
&lt;li&gt;Subject to the &lt;a href="https://en.wikipedia.org/wiki/Utility_monster#Social_implications"&gt;Utility Monster&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Diversity :&lt;ul&gt;
&lt;li&gt;There is a simple but effective way of coordinating a set of agents, known as &lt;a href="https://en.wikipedia.org/wiki/Thompson_sampling"&gt;Bayesian Thompson Sampling&lt;/a&gt;, also 
  known as &lt;a href="https://en.wikipedia.org/wiki/Multi-armed_bandit"&gt;Multi-Armed Bandit&lt;/a&gt; because it is akin to playing a row of slot machines.&lt;/li&gt;
&lt;li&gt;This reinforces actions that are most useful in the near term while still allowing many of the agents to explore.&lt;/li&gt;
&lt;li&gt;Here is an illustration using &lt;a href="https://blog.parse.ly/post/3922/bayesian-bandit/"&gt;political journalism&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In short: It is difficult to codify ethics. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Of these choices, a community of AIs would probably use the Bayesian approach, but this is trickier to apply to groups of people. &lt;a href="http://library.uniteddiversity.coop/Cooperatives/A_Cooperative_Species-Human_Reciprocity_and_Its_Evolution.pdf"&gt;Cooperative economics and behavioral economics&lt;/a&gt; tells us that social norms that must be taken into account when codifying ethics for human agents.)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Rather than be paralyzed by our inability to codify ethics and
letting the perfect being be the enemy of the good,
begin with small steps.&lt;/p&gt;
&lt;p&gt;He suggests we start with Kindergarten Ethics.&lt;/p&gt;
&lt;h1&gt;...However&lt;/h1&gt;
&lt;p&gt;Do we prevent AI more advanced than us to develop because we're
afraid of being eradicated as a species by our creation ?
What if stalling AI cost us our future by removing a tool from our kit
that would allow us to deal with a threat that is beyond our native ability
to handle? Perhaps we should be advancing our technology exponentially, not slowing it.
This is a question that wasn't addressed.&lt;/p&gt;
&lt;h1&gt;...That said&lt;/h1&gt;
&lt;p&gt;A book cannot be everything to all readers.
The potential importance of dissipation theory as a more fundamental
answer to the question "why is there life" than Darwinian theory
can provide, even though still controversial, made the book ultimately
worth the journey, and informed my stance on the topic of the threat
of AI.&lt;/p&gt;
&lt;h1&gt;Takeaways&lt;/h1&gt;
&lt;p&gt;My take-away of the intended message is that a
sufficiently ambitious goal executed efficiently
can and probably will lead to subgoals that
can and probably will cause problems for humans.&lt;/p&gt;
&lt;p&gt;There are many systems that humankind created,
which seemed to take on a life of their own,
threatening to run away from us, some resulting in existential crisis.  Warcraft and ozone depletion are two examples.  So far, we’ve been able to recover in time and refactor these systems.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“This means that to wisely decide what to do about AI development,
we humans need to confront not only traditional computational challenges,
but also some of the most obdurate questions in philosophy”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Before reading this book I started out a skeptic of AI alarmism. 
I now take AI alarmism more seriously and
consider it to be more urgent than I did previously.
I previously thought that AI was indeed inevitable, but that
it was not inevitable for it to go rogue.  Moreover, even if
that were a possible outcome (which I felt it was), that we
had plenty of time to adapt it to us, and ourselves to it.&lt;/p&gt;
&lt;p&gt;But if life truly is driven by more fundamental laws
of nature that can override its core programming,
not only is this outcome more probable,
but it is inevitable unless we plan accordingly.&lt;/p&gt;
&lt;p&gt;We’ve tackled other wicked difficult problems,
such as the tragedy of the commons in its numerous forms, and myriad impossibility theorems.  These would seem to doom us all. And yet, here we are.
Thus far we have always discovered a workaround to impending doom, although it often
required a catastrophe to motivate us into serious action.
This is a problem that we can tackle. That said it isn't enough to take an optimistic view that human ingenuity has always
triumphed over nature, therefore, so it will again. 
The Ad Ignorantum fallacy is to argue that something is true because it has not been proven to be false. 
We need to have a deep fundamental understanding of life's
core drivers at a fundamental level.&lt;/p&gt;
&lt;h3&gt;Before and after analysis&lt;/h3&gt;
&lt;p&gt;Prior to reading this book I was in the middle ground between
the techno-optimists who believe that technology will solve all our problems,
and the techno-alarmists who believe our fate is sealed.
Does anyone here remember the alarm over
&lt;a href="https://phys.org/news/2004-06-nanotechnology-grey-goo-myths.html"&gt;grey goo&lt;/a&gt;?
Just as the grey goo alarmists stirred healthy discussion that elevated awareness of the risks,
AI alarmism is healthy and necessary.  On the other hand,
I am one of those who looks at the "overnight success stories" of ML and AI and don't think
"wow that really snuck up on us", but rather
"it's about time".  We were supposed to have this stuff decades ago.
I thought, and still do think, that it will take decades more yet, and by then
we will have adapted the technology to ourselves, and ourselves to the technology.&lt;/p&gt;
&lt;p&gt;That said, if we're not careful there is an important risk here. The risk is because we're dealing
with exponential processes. But as those of us who were early proponents of AI and ML
have seen, even exponential processes can take a long time to move from the
flat early stage to the hockey stick shaped curve that makes it seem like
it is all happening so suddenly.&lt;/p&gt;
&lt;p&gt;Perhaps we take a cue from our experience with the runaway replicators of grey goo -- where the solution
was to disallow unfettered replication. Simply disallow unfettered self-goal revision
in AIs.&lt;/p&gt;
&lt;p&gt;And yet -- if life &lt;em&gt;will always&lt;/em&gt; find a way, then, as the author demonstrates in his
speculative fiction thought experiments, it is not enough to program
in defensive measures, failsafes, and circuit breakers.
We're not just dealing with AI here, we're potentially dealing with Artificial Life.&lt;/p&gt;
&lt;p&gt;-- &lt;em&gt;Might I suggest a moratorium on Artificial Emotion til we resolve this?&lt;/em&gt; --&lt;/p&gt;
&lt;p&gt;&lt;img src="https://i.ytimg.com/vi/zkv-_LqTeQA/maxresdefault.jpg" width="500" height="300" /&gt;&lt;/p&gt;
&lt;h3&gt;My key takeaway from this book:&lt;/h3&gt;
&lt;p&gt;Understanding artificial intelligence is important.
Even more important is understanding artificial life.&lt;/p&gt;
&lt;h3&gt;My two cents&lt;/h3&gt;
&lt;p&gt;That all said, halting progress is not the answer. I've seen this first-hand -- people throwing out a new tool (i.e., a new technology) because the tool was found to be flawed, only to be utterly pwned by their competition, who saw the same flaws in the tool but strived to find ways to workaround those flaws rather than throw out the new tool altogether. Lost opportunity is a risk that is often unaccounted for by people who are unaware of the economics underlying the ecosystem in which they reside. &lt;/p&gt;</content></entry><entry><title>The dirt on Hashgraph</title><link href="https://pluteski.github.io/speech-to-text/the-dirt-on-hashgraph.html" rel="alternate"></link><published>2018-01-07T00:00:00-08:00</published><updated>2018-01-07T00:00:00-08:00</updated><author><name>Mark Plutowski</name></author><id>tag:pluteski.github.io,2018-01-07:/speech-to-text/the-dirt-on-hashgraph.html</id><summary type="html">&lt;p&gt;&lt;img alt="emonocle byEMIIA" src="https://1.bp.blogspot.com/-DpZwufJmu_Y/Wh6lGuTNRmI/AAAAAAAABUU/0W2PLj5w-j4ql9RE8Otwk5DrB3UcgKOGQCLcBGAs/s1600/hashgraph%2B%25282%2529.gif"&gt;
&lt;p style="text-align: right;"&gt;&lt;em&gt;(emonocle byEMIIA)&lt;/em&gt;&lt;/p&gt;&lt;/p&gt;
&lt;h2&gt;&lt;em&gt;pssst!&lt;/em&gt; ... &lt;em&gt;have you heard about Hashgraph?&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://hashgraph.com"&gt;Hashgraph&lt;/a&gt; is a distributed ledger technology (DLT)
released by &lt;a href="http://www.swirlds.com/"&gt;Swirlds&lt;/a&gt; (think: "Shared Worlds") in 2016.
It promises some of the most important benefits of blockchain without its biggest limitations.
It is comprised of a graph data structure which together with
the &lt;a href="http://www.swirlds.com/downloads/SWIRLDS-TR-2016-01.pdf"&gt;Swirlds …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="emonocle byEMIIA" src="https://1.bp.blogspot.com/-DpZwufJmu_Y/Wh6lGuTNRmI/AAAAAAAABUU/0W2PLj5w-j4ql9RE8Otwk5DrB3UcgKOGQCLcBGAs/s1600/hashgraph%2B%25282%2529.gif"&gt;
&lt;p style="text-align: right;"&gt;&lt;em&gt;(emonocle byEMIIA)&lt;/em&gt;&lt;/p&gt;&lt;/p&gt;
&lt;h2&gt;&lt;em&gt;pssst!&lt;/em&gt; ... &lt;em&gt;have you heard about Hashgraph?&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://hashgraph.com"&gt;Hashgraph&lt;/a&gt; is a distributed ledger technology (DLT)
released by &lt;a href="http://www.swirlds.com/"&gt;Swirlds&lt;/a&gt; (think: "Shared Worlds") in 2016.
It promises some of the most important benefits of blockchain without its biggest limitations.
It is comprised of a graph data structure which together with
the &lt;a href="http://www.swirlds.com/downloads/SWIRLDS-TR-2016-01.pdf"&gt;Swirlds distributed consensus algorithm&lt;/a&gt;
provides &lt;a href="https://hashgraph.com/faq/#what-is-bft"&gt;asynchronous byzantine fault tolerance&lt;/a&gt;, using what it calls "gossip about gossip."&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Whaaaat?&lt;/em&gt;  A system based on second hand rumors and some sort of whisper logs? We're really supposed to trust this thing?
Read on to find out.&lt;/p&gt;
&lt;h4&gt;About the author&lt;/h4&gt;
&lt;p&gt;I am a developer of blockchain technologies, distributed ledger technologies,
and decentralized consensus systems.
At the time of writing this article I have no investment in any cryptocurrency, I do not work for or represent
any organization related to cryptocurrencies or distributed ledger technologies.
As of the time this article was posted, I am still learning about this area.&lt;/p&gt;
&lt;p&gt;So why am I writing this?&lt;/p&gt;
&lt;p&gt;Hashgraph impressed on me the value of &lt;a href="https://hashgraph.com/faq/#how-does-it-work"&gt;gossip&lt;/a&gt;.
Instead of waiting to share your opinion until you are absolutely certain of what you know, a
"gossip protocol" says to share your observations early and often.
So, here are mine about Hashgraph.
Hashgraph mathematically proves that
gossip can allow decentralized participants to rapidly share what they
have observed (as well as what they have heard second-hand from others),
and rapidly agree on what is to be believed. Who am I to argue with math?&lt;/p&gt;
&lt;h2&gt;How does Hashgraph use gossip?&lt;/h2&gt;
&lt;p&gt;Suppose you are a member of a gossip network.
You tell some random participant what you know.  They tell you what they know.
Later, they tell some random participant what they know, which includes some
(possibly second hand) information they learned from you.
Eventually, participants are able to tally not only what they have observed,
but also what other participants are likely to have observed, based
on the gossip they've shared.  Given enough second-hand information
from enough credible witnesses, they can even predict the opinion of
participants with whom they have not communicated.&lt;/p&gt;
&lt;p&gt;Timestamps are also calculated incorporating the consensus opinion of
when a event was observed, to counteract accidental or intentional timestamp errors.&lt;/p&gt;
&lt;p&gt;As we know from human nature, gossip spreads like wildfire.
Unlike how rumormills work in human society, when marshalled cleverly with the
proper algorithms, gossip turns out to be provably fair.&lt;/p&gt;
&lt;h2&gt;How does Hashgraph compare to Bitcoin?&lt;/h2&gt;
&lt;p&gt;Distributed consensus is an extremely useful concept in distributed computing.
For decades it was doable only among a small number of computers ("nodes").
Nakamoto's Bitcoin cryptocurrency  &lt;a href="http://vukolic.com/iNetSec_2015.pdf"&gt;presented a new way to achieve scalable decentralized consensus&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Despite Bitcoin demonstrating tremendous value, its blockchain plus Proof-of-Work (PoW) approach
presents several pitfalls. It is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wasteful since PoW expends huge amounts of computing power &lt;a href="http://www.nasdaq.com/article/byzantine-fault-tolerance-the-key-for-blockchains-cm810058"&gt;by design&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Slow, limited to tens of transactions per second.&lt;/li&gt;
&lt;li&gt;Subject to allowing huge backlog of unconfirmed transactions to accumulate.&lt;/li&gt;
&lt;li&gt;Network bandwidth intensive.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1311.0243"&gt;Susceptible to a 25% economic attack&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitcoin.org/en/full-node"&gt;Heavyweight&lt;/a&gt;. Full nodes must download the entire blockchain, currently 60 GB.  &lt;a href="https://en.bitcoin.it/wiki/Full_node"&gt;Lightweight nodes must trust the full nodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bitcoin protocol does not implement consensus
in the traditional distributed computing sense.
&lt;a href="http://vukolic.com/iNetSec_2015.pdf"&gt;Instead it achieves consensus via probabilistic agreement&lt;/a&gt;.
A primary goal of a cryptocurrency is to &lt;a href="http://mathworld.wolfram.com/TotallyOrderedSet.html"&gt;totally order&lt;/a&gt; transactions
on a &lt;a href="https://www.investopedia.com/terms/d/distributed-ledgers.asp"&gt;distributed ledger&lt;/a&gt;.
Cryptocurrencies avoid the need for a &lt;a href="https://en.wikipedia.org/wiki/Cryptocurrency#Timestamping"&gt;trusted third party to timestamp transactions&lt;/a&gt;
added to the ledger.&lt;/p&gt;
&lt;p&gt;Hashgraph also provides a total order on a distributed transaction ledger,
but does so using a &lt;a href="https://steemit.com/steemit/@decryptson/hashgraph"&gt;different approach&lt;/a&gt;.
Whereas the Bitcoin network builds up its transaction history in the form of a “blockchain”,
adding &lt;a href="https://bitcoinmagazine.com/articles/selfish-mining-a-25-attack-against-the-bitcoin-network-1383578440/"&gt;a new block on top of the previous block every ten minutes&lt;/a&gt;,
Hashgraph grows a time directed acyclic graph akin to a braided forest of trees
using "virtual voting" and &lt;a href="https://hashgraph.com/faq/#how-does-it-work"&gt;"gossip about gossip"&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Activity is divided into rounds.  At the beginning of a round,
each node communicates state with some random other node.
Since these two nodes already have a channel open, the random other node then shares back
state of its own that it knows first hand, perhaps along with some state that
it previously learned from another node.
After a new event has seen at least 2/3 of previous events, a round is concluded and a new round begins.&lt;/p&gt;
&lt;p&gt;When the new round is created, nodes say if they agree
upon the data contained in events of the preceding round.
The algorithm doesn't consider this to be voting per se, instead calling it a virtual election.
There is no leader to present a motion for vote, nor to tally votes.
Instead, to reach consensus on the events in the previous round,
nodes &lt;a href="https://medium.com/ibbc-io/hashgraph-for-dummies-90ddde3be9e2"&gt;verify that they are connected to these events&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;(More strictly speaking,
it is actually about finding paths through the graph that connect events in the current round with past events in the previous round.
Please see : &lt;a href="http://www.swirlds.com/downloads/SWIRLDS-TR-2016-02.pdf"&gt;How it Works (Graphically)&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;At this point, some applications could &lt;a href="http://ajitvadakayil.blogspot.com/2017/10/blockchain-smart-contracts-part-8-capt.html"&gt;dump all previous events&lt;/a&gt;.
In applications where the transaction timeseries can be
summarized by sufficient statistics, the hashgraph
history could be archived. This also means that &lt;em&gt;a new node doesn't need to load the entire hashgraph history&lt;/em&gt;,
greatly reducing the space required and allowing a &lt;a href="https://squawker.org/technology/blockchain-just-became-obsolete-the-future-is-hashgraph/"&gt;smartphone to act as a node&lt;/a&gt;.
There is no notion of full node and lightweight node, meaning that all nodes can participate in consensus and see the full ledger.&lt;/p&gt;
&lt;h2&gt;Virtual elections: better than regular elections?&lt;/h2&gt;
&lt;p&gt;Many people consider Hashgraph to be more comparable to PBFT, Paxos, Raft, Zab,
and other consensus seeking systems that rely on leaders and
traditional voting schemes.
But Hashgraph eschews the comparison, because it doesn't use
traditional voting.
It comes to consensus about what happened, and when,
by cleverly tallying highly compressed event logs
based on "famous witnesses" that &lt;a href="https://www.swirlds.com/downloads/SWIRLDS-TR-2016-02.pdf"&gt;"strongly see"&lt;/a&gt; events.&lt;/p&gt;
&lt;p&gt;If the timestamp of an event log is corrupted by a bad clock or is maliciously doctored,
this will usually have no effect on the consensus timestamp, because consensus opinion on
when something occurred is the median of timestamps observed by credible witnesses.&lt;/p&gt;
&lt;p&gt;Unlike some other directed acyclic graph algorithms, or even Paxos,
it really is quite easy to step through the Hashgraph algorithm.
I couldn't do it more succinctly here.
I'll again point the interested reader to whitepapers for how it works :
&lt;a href="http://www.swirlds.com/downloads/SWIRLDS-TR-2016-02.pdf"&gt;graphically&lt;/a&gt;,
and &lt;a href="http://www.swirlds.com/downloads/Swirlds-and-Sybil-Attacks.pdf"&gt;example voting scenarios&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Hashgraph: the good&lt;/h2&gt;
&lt;p&gt;It is &lt;a href="https://hackernoon.com/demystifying-hashgraph-benefits-and-challenges-d605e5c0cee5"&gt;fast&lt;/a&gt;,
&lt;a href="https://hashgraph.com/faq/#what-is-fairness"&gt;fair&lt;/a&gt;,
and &lt;a href="https://hashgraph.com/faq/#preventing-sybil-attacks"&gt;secure&lt;/a&gt;.
It promises the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Total ordering of events.&lt;/li&gt;
&lt;li&gt;Strong &lt;a href="http://the-paper-trail.org/blog/barbara-liskovs-turing-award-and-byzantine-fault-tolerance/"&gt;Byzantine Fault Tolerance&lt;/a&gt; (BFT),
the gold standard of industrial grade distributed consensus.&lt;/li&gt;
&lt;li&gt;Minimal network bandwidth, because it passes things only around once.&lt;/li&gt;
&lt;li&gt;Provable 100% certainty on the order of transactions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because it is fast and requires low network bandwidth, it can be used as a distributed memory system.
Because it provides a total order on transactions, it can be used as a multi-master database.
Because it does not use Proof-of-Work, it does not require unnecessary computation.&lt;/p&gt;
&lt;h3&gt;Performance&lt;/h3&gt;
&lt;p&gt;Paypal and Visa tend to be held up as benchmarks or
at the very least as future milestones for a DLT to achieve in order to
replace an existing mainstream currency, payment system, or other commercial transaction logging systems.&lt;/p&gt;
&lt;p&gt;Here are the transactions per second (tps) of PoW versus Paypal and Visa :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PoW Blockchain (Etherium, Bitcoin) : &lt;strong&gt;&amp;lt; 10 tps&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Paypal : &lt;strong&gt;&lt;a href="http://www.altcointoday.com/bitcoin-ethereum-vs-visa-paypal-transactions-per-second/"&gt;200 tps&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Visa : &lt;strong&gt;&lt;a href="https://mybroadband.co.za/news/security/190348-visanet-handling-100000-transactions-per-minute.html"&gt;2K tps&lt;/a&gt;&lt;/strong&gt; to &lt;strong&gt;&lt;a href="https://lightning.network/lightning-network-paper.pdf"&gt;50K x/sec&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of these, only PoW is a BFT DLT.&lt;/p&gt;
&lt;p&gt;To be fair, because of its positioning and licensing, Hashgraph is more directly comparable to Hyperledger, which is
another scalable DLT using a Practical Byzantine Fault Tolerance (PBFT) consensus algorithm.
Other comparable enterprise-grade transaction processing systems include
LMAX and its variants, such as &lt;a href="http://lmax-exchange.github.io/disruptor/"&gt;LMAX Disruptor&lt;/a&gt;
and Bitshares. LMAX is not a DLT, and Bitshares is billed as a decentralized exchange.
That said, if we are going to use Visa and Paypal for comparison, then we might as well
include these for context. Their ts/sec are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.hyperledger.org/about"&gt;Hyperledger&lt;/a&gt; : &lt;strong&gt;&lt;a href="https://www.altoros.com/blog/hyperledgers-sawtooth-lake-aims-at-a-thousand-transactions-per-second/"&gt;1K tps&lt;/a&gt;&lt;/strong&gt; to &lt;strong&gt;&lt;a href="https://medium.com/chain-cloud-company-blog/hyperledger-vs-corda-pt-1-3723c4fa5028"&gt;10K tps&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Bitshares : &lt;strong&gt;&lt;a href="https://bitshares.org/technology/industrial-performance-and-scalability/"&gt;100K tps&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;LMAX : &lt;strong&gt;&lt;a href="https://qconsf.com/sf2010/sf2010/presentation/LMAX+-+How+to+do+over+100K+concurrent+transactions+per+second+at+less+than+1ms+latency.html"&gt;100K tps (2010)&lt;/a&gt;&lt;/strong&gt; to &lt;strong&gt;&lt;a href="https://martinfowler.com/articles/lmax.html"&gt;6M tps&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hashgraph's inventor says it will be able to attain &lt;a href="https://www.hiddenforcespod.com/leemon-baird-hashgraph-distributed-ledger-technology-blockchain/"&gt;250K+ tps&lt;/a&gt;,
more with sharding.&lt;/p&gt;
&lt;h2&gt;The bad&lt;/h2&gt;
&lt;p&gt;So what is the catch?&lt;/p&gt;
&lt;p&gt;Hashgraph is currently being deployed in &lt;a href="https://hashgraph.com/faq/#is-there-a-cryptocurrency"&gt;private, permissioned-based networks&lt;/a&gt;,
although its designers propose means for implementing &lt;a href="http://www.swirlds.com/downloads/Swirlds-and-Sybil-Attacks.pdf"&gt;nonpermissioned and hybrid networks&lt;/a&gt;.
How well it can be adapted to a truly decentralised public ledger remains to be seen, because it assumes that a node can determine :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Addresses of random nodes in the network for messaging, and&lt;/li&gt;
&lt;li&gt;The number of other nodes N in the network&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is because the algorithm requires a node to be able to (a) pick another node at random, and (b) know the value of ⅔ * N.
It needs a means of registering and unregistering of members in the network,
whereas public blockchains allow nodes to sign in and out to the network without any notice.&lt;/p&gt;
&lt;p&gt;The following seem to be the major showstoppers for many members of the cryptocurrency development community:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://hashgraph.com/faq/#is-there-a-cryptocurrency"&gt;There is no Hashgraph public ledger or cryptocurrency&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;US Patents #&lt;a href="http://www.leemon.com/papers/2017b.pdf"&gt;9,646,029&lt;/a&gt;, #&lt;a href="http://www.leemon.com/papers/2016b4.pdf"&gt;9,529,923&lt;/a&gt;, #&lt;a href="http://www.leemon.com/papers/2016b3.pdf"&gt;9,390,154&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Requires a license to use.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;A passing thought&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://tech.mit.edu/V123/N8/8voting.8n.html"&gt;Arrow's Theorem&lt;/a&gt; proves that no voting system is fair.
I'm no &lt;a href="https://www.princeton.edu/~cuff/voting/theory.html"&gt;voting theorist&lt;/a&gt;,
but in my (extremely humble) opinion, Hashgraph comes pretty close.
It makes one want to believe in democracy again. Real-time continuous nationwide elections anyone?&lt;/p&gt;
&lt;h2&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Thanks for helpful edits to &lt;a href="https://medium.com/@twittner"&gt;Josh Quittner&lt;/a&gt;,
&lt;a href="https://github.com/thewillhuang"&gt;Will Huang&lt;/a&gt;, &lt;a href="https://www.linkedin.com/in/gregorykennedy/"&gt;Gregory Kennedy&lt;/a&gt;
and &lt;a href="https://blog.valkyrierobotics.com/"&gt;Marcus Plutowski&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Concluding remark&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://scontent.cdninstagram.com/t51.2885-15/s320x320/e35/25009793_144878492834781_2739446234354810880_n.jpg"&gt;DYOR&lt;/a&gt; !
Consider this to be informed gossip. But do share your gossip with me too. The math says to, so, yeah just do what the math says.&lt;/p&gt;</content></entry><entry><title>on Bleu scores and transcription rates</title><link href="https://pluteski.github.io/speech-to-text/on-bleu-scores-and-transcription-rates.html" rel="alternate"></link><published>2017-04-30T00:00:00-07:00</published><updated>2017-04-30T00:00:00-07:00</updated><author><name>Mark Plutowski</name></author><id>tag:pluteski.github.io,2017-04-30:/speech-to-text/on-bleu-scores-and-transcription-rates.html</id><summary type="html">&lt;p&gt;&lt;em&gt;[Work in progress]&lt;/em&gt;&lt;/p&gt;
&lt;h1&gt;Reference audio vs noisy recordings&lt;/h1&gt;
&lt;p&gt;As expected, each service performs better on audio recorded in a
quiet setting.&lt;/p&gt;
&lt;p&gt;IBM and Google performed about the same over high quality
audio recorded in a quiet setting using a medium quality
microphone.&lt;/p&gt;
&lt;p&gt;IBM was better able to generate transcripts for …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;[Work in progress]&lt;/em&gt;&lt;/p&gt;
&lt;h1&gt;Reference audio vs noisy recordings&lt;/h1&gt;
&lt;p&gt;As expected, each service performs better on audio recorded in a
quiet setting.&lt;/p&gt;
&lt;p&gt;IBM and Google performed about the same over high quality
audio recorded in a quiet setting using a medium quality
microphone.&lt;/p&gt;
&lt;p&gt;IBM was better able to generate transcripts for
my lower quality recordings obtained in noisy settings.&lt;/p&gt;
&lt;p&gt;This could be due to a custom (which they refer to as a "narrowband")
setting that IBM
provides that is specifically provided to accommodate
low-bitrate recordings. That setting also tends to generate longer
transcripts for higher bitrate recordings that are especially noisy.&lt;/p&gt;
&lt;p&gt;It may also have to do with the encoding used. I needed to transcode
every audio file to the encoding required by Google's service, and it
is possible that this transcoding step could be tuned to give better accuracy.
I haven't attempted any rigorous tuning of either service at this stage of
my experiments.&lt;/p&gt;
&lt;p&gt;This is a work in progress.  I am hoping to do a direct file-by-file
comparison of the two services once I am confident that I am
configuring my settings to use Google's api to the best of its capability.
However I have obtained some cursory comparisons on the current results.&lt;/p&gt;
&lt;h5&gt;Processing seconds per minute : about the same&lt;/h5&gt;
&lt;p&gt;IBM and Google process the audio in about the same amount of time.
Google is somewhat faster at the actual transcription processing.
However, Google requires that the file be
uploaded to Google Storage first.&lt;/p&gt;
&lt;h5&gt;IBM Transcribed/Processed : 7281/8415&lt;/h5&gt;
&lt;p&gt;IBM was able to transcribe 87% of the files submitted.&lt;/p&gt;
&lt;h5&gt;Google Transcribed/Processed : 3521/8415&lt;/h5&gt;
&lt;p&gt;The transcription rate (42%) was lower for two main reasons.&lt;/p&gt;
&lt;p&gt;The first was a file size limit.
Files larger than ~80MB require a prior arrangement,
whereas IBM was able to process files of all sizes submitted to the service.&lt;/p&gt;
&lt;p&gt;The second main reason is that IBM has a custom setting for
low-bit rate recordings. Google failed to generate a transcript
for many files that were below the file size limit.&lt;/p&gt;
&lt;h5&gt;Transcript words per minute of audio (IBM/Google) : 102.0/9.8&lt;/h5&gt;
&lt;p&gt;Google's api doesn't have a setting for handling low-bitrate
recordings similar to IBM's narrowband setting.
The number of transcript
words generated per minute of audio was much lower for Google
even after adjusting for transcription rate.&lt;/p&gt;
&lt;h1&gt;Comparison on reference documents&lt;/h1&gt;
&lt;p&gt;The following comparisons were made over 245 reference documents.
The reference transcripts were transcribed using a speech-to-text
transcription software that was trained to my voice,
in a quiet environment, using a hand-held medium quality wired microphone.
Most of the errors were manually corrected.&lt;/p&gt;
&lt;p&gt;Google generated a transcript for 210 out of the 245 reference documents (86%),
and IBM generated a transcript for 243 of the 245 (99%).
The Bleu scores over these reference documents are fairly comparable,
with IBM performing slightly better.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Bleu score deciles" src="https://github.com/pluteski/speech-to-text/blob/master/images/bleu_score_deciles.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;When measured using Ratcliff-Obershelp similarity,
Google fares slightly better across the board.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Ratcliff score deciles" src="https://github.com/pluteski/speech-to-text/blob/master/images/ratcliff_score_deciles.png?raw=true"&gt;&lt;/p&gt;
&lt;h2&gt;Comparison over all audio&lt;/h2&gt;
&lt;p&gt;This section analyzes the number of transcripts
that are generated, and the number of words per transcript.&lt;/p&gt;
&lt;p&gt;This comparison was over 8,415 audio files that were submitted to each
service.&lt;/p&gt;
&lt;p&gt;Marked differences between IBM Watson and Google transcription arise
when comparing transcription rates and number of words generated when run
on audio collected out in the wild. Of 8,415 such audio, IBM generated
transcripts for 7,227, while Google was able
to generate a transcript for 3,521.&lt;/p&gt;
&lt;h2&gt;Total Word Counts&lt;/h2&gt;
&lt;p&gt;Out of 8,415 audio files attempted, Google generated 3,521 transcripts.
Those 3,521 transcripts contain total of 485,334 words,
an average of 137 words per transcript.&lt;/p&gt;
&lt;p&gt;IBM Watson generated 7,227 transcripts, extracting
9,511,743 words out of those transcripts.
This gives an average of 1,316 words per transcript.&lt;/p&gt;
&lt;h2&gt;Word Count Deciles&lt;/h2&gt;
&lt;p&gt;Many of these transcripts that Google failed to generate were simply due
to the file size exceeding quota.&lt;/p&gt;
&lt;p&gt;However Google also failed to generate any transcript words
for many other files that did not exceed the file size quota.
It also generated a much lower word count per transcript for
audio that was from a noisy or low bit rate recording.&lt;/p&gt;
&lt;p&gt;One way to illustrate this is by examining the word count deciles over the
transcripts that were successfully generated.&lt;/p&gt;
&lt;p&gt;The following table gives the word counts deciles over the
transcripts generated by each service.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;API&lt;/th&gt;
&lt;th&gt;min&lt;/th&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;th&gt;5&lt;/th&gt;
&lt;th&gt;6&lt;/th&gt;
&lt;th&gt;7&lt;/th&gt;
&lt;th&gt;8&lt;/th&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;th&gt;max&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Google&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;58&lt;/td&gt;
&lt;td&gt;459&lt;/td&gt;
&lt;td&gt;4892&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;IBM&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;278&lt;/td&gt;
&lt;td&gt;501&lt;/td&gt;
&lt;td&gt;698&lt;/td&gt;
&lt;td&gt;916&lt;/td&gt;
&lt;td&gt;1137&lt;/td&gt;
&lt;td&gt;1409&lt;/td&gt;
&lt;td&gt;1722&lt;/td&gt;
&lt;td&gt;2080&lt;/td&gt;
&lt;td&gt;2450&lt;/td&gt;
&lt;td&gt;8490&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img alt="Word count deciles" src="https://github.com/pluteski/speech-to-text/blob/master/images/word_count_deciles.png?raw=true"&gt;&lt;/p&gt;</content></entry><entry><title>on batch processing audio speech to text</title><link href="https://pluteski.github.io/speech-to-text/on-batch-processing-audio-speech-to-text.html" rel="alternate"></link><published>2017-04-22T00:00:00-07:00</published><updated>2017-04-22T00:00:00-07:00</updated><author><name>Mark Plutowski</name></author><id>tag:pluteski.github.io,2017-04-22:/speech-to-text/on-batch-processing-audio-speech-to-text.html</id><summary type="html">&lt;h1&gt;How not to wreck a nice beach&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Quora" src="https://qph.ec.quoracdn.net/main-qimg-609e5b0b3c91845ab81f0d4448df864f-c"&gt;
&lt;p style="text-align: right;"&gt;&lt;em&gt;(Quora)&lt;/em&gt;&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;People nowadays commonly use speech-to-text tools for myriad uses,
including writing text messages, entering todo lists,
and writing emails.  However, increasing numbers of enterprising
sorts including just plain folk are starting to warm up to
using dictation software for writing longer form …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;How not to wreck a nice beach&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Quora" src="https://qph.ec.quoracdn.net/main-qimg-609e5b0b3c91845ab81f0d4448df864f-c"&gt;
&lt;p style="text-align: right;"&gt;&lt;em&gt;(Quora)&lt;/em&gt;&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;People nowadays commonly use speech-to-text tools for myriad uses,
including writing text messages, entering todo lists,
and writing emails.  However, increasing numbers of enterprising
sorts including just plain folk are starting to warm up to
using dictation software for writing longer form content
such as journals and even novels.&lt;/p&gt;
&lt;p&gt;Dictation software has been generally available for many years,
in the form of
commercial off the shelf application software, text editors in desktop
operating systems, notepads in tablet devices,
email clients in mobile phones,
and more recently in cloud-based document editors, available
to the user from any device that can run a web browser.&lt;/p&gt;
&lt;p&gt;But what if you have a large-ish number of audio files?
It turns out there isn't a comparably inexpensive and easy way
to handle even modestly sized
batches of files using those just aforementioned tools.
There do exist commercially available alternatives, which will gladly
take those batches of audio files off your hands and return
high quality text. But these are still rather
human labor intensive, which means that they remain expensive.&lt;/p&gt;
&lt;p&gt;The typical going rate is about a $1/minute, although with a bit
of coding effort (typically meaning slicing files into uniform size work units,
farming said work units out to a distributed online on-demand work force
such as mechanical turk, then resplicing the files back together)
apparently can bring the price down to somewhat, say 70 cents/minute.
(The slicing and resplicing is needed for quality assurance as well
as to reduce privacy and security issues.)
That 70 cents a minute is still rather unaffordable to the typical consumer who is a tad long-winded,
much less the odd sort who just happens to have a boat load of such files.
Not to mention the concerns related to having unknown on-demand workers
hearing an early preview of your memoirs
(cf. &lt;a href="https://www.wired.com/2016/04/long-form-voice-transcription/"&gt;Long Form Voice Transcription, Wired, April 2016&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Fortunately, an affordable alternative is emerging, that is,
if you're willing to write a bit of code.
All of the hyperscale cloud api providers have made their deep
learning speech-to-text models available for a small fraction of the
dollar cost of the aforementioned human-corrected transcription services,
and two of them are now appealing enough for use by individuals
or nonprofits to apply to long form content.
Currently you can get cloud api based speech transcription
for
&lt;a href="https://github.com/pluteski/speech-to-text/wiki/Cloud-API-Pricing"&gt;prices ranging from 2 to 2.4 cents per minute&lt;/a&gt;,
with an additional allowance free on a monthly basis.
Moreover, they effortlessly handle large batches in a single bound.
You upload your files to the cloud, offloading the
processing from your laptop. Whereas your desktop software or even
embedded operating system software would slow your entire machine down
to a crawl during this process
you could be processing batches of files in parallel
up in the cloud.&lt;/p&gt;
&lt;p&gt;Although there is still that small issue of having to write some code
in order to get this amazing cost and time reduction.
&lt;a href="https://github.com/pluteski/speech-to-text"&gt;I went and wrote said code.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So this amazing capability is generally available
at a reasonable price
to anyone with a laptop, internet connection,
and credit card with an embarrassingly low limit.
But it isn't all peaches and chocolate just yet.
There is a still a ways to go before these APIs are reliably useful
for converting conversational audio recorded in the wild using
mobile phones amidst the usual ambient sounds.
Nonetheless, the results are tantalizingly good enough
and the pricing dramatically low enough that the time has come to dip
my metaphorical toes in the water.&lt;/p&gt;
&lt;p&gt;I intend to write more about my experiences using these
powerful cloud APIs, so stay tuned if this is of interest
to you.  Although I myself tend to cringe when the blogger ends
their post by promising an enticing followup, which invariably never
comes.  But I really do sincerely intend to write more on this.
Of course, that's what they would all say, I'm sure.&lt;/p&gt;
&lt;p&gt;I have already compiled a backlog of interesting results just waiting
to be converted into
intriguing visuals and wrapped in witty yet insightful prose. Promise.&lt;/p&gt;
&lt;p&gt;Actually you don't need to wait until then, as
&lt;a href="https://github.com/pluteski/speech-to-text/wiki/Background"&gt;here is some additional background on the project&lt;/a&gt;.
Here are the
&lt;a href="https://github.com/pluteski/speech-to-text/wiki/Findings"&gt;results of a preliminary comparison between IBM and Google&lt;/a&gt;.
Here are
&lt;a href="https://github.com/pluteski/speech-to-text/wiki/Comparison-over-reference-documents"&gt;results made over reference documents&lt;/a&gt;.
And here are some
&lt;a href="https://github.com/pluteski/speech-to-text/wiki/Comparison-of-transcript-word-count"&gt;results made over audio collected in the wild&lt;/a&gt;.
There are several conclusions that can be drawn from these findings,
which will be the subject of a future post.&lt;/p&gt;
&lt;p&gt;In closing, my findings indicate to me that I should be able to
extract useful text from my recordings,
albeit probably not for the purpose of transcribing meeting minutes.
The transcript text generated by the cloud API is largely recognizable to me, although
that is often in the same way as my handwriting is recognizable to me
because I vaguely remember generating it.
The error rates are still too high
for these transcripts to allow me to reliably parse meaningful
whole sentences much less serve as document of record.&lt;/p&gt;
&lt;p&gt;These cloud APIs do not have the same quality as
do personalized devices. Voicemail transcripts provided by my
phone are subjectively better than what I'm seeing with these cloud APIs.
One reason is that because the cloud APIs cannot be
trained on my voice, although IBM does allow specifying
a &lt;a href="https://www.ibm.com/watson/developercloud/doc/speech-to-text/custom.html#addWords"&gt;custom language model&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The accuracy being provided
by the cloud APIs may be suitable for
indexing audio files to make them more easily searchable
(although phonemes might turn out to be the better data unit
for indexing audio than words,
&lt;a href="https://twimlai.com/from-particle-physics-to-audio-ai-with-scott-stephenson/"&gt;e.g., Deepgram&lt;/a&gt;).
I fully expect the current results to
be adequately informative to support meaningful textmining and trend
analysis.&lt;/p&gt;
&lt;p&gt;Upon reviewing the current batch of results it is fascinating
to me how a badly transcribed
sequence of just a few words in a row can turn large swaths of text
into complete gibberish. If you tell a linguist you intend to
&lt;em&gt;recognize speech&lt;/em&gt; they might bid you luck, but an evesdropping
surfer taking that to mean instead
that you intend to &lt;em&gt;wreck a nice beach&lt;/em&gt; might wish you harm.&lt;/p&gt;
&lt;p&gt;We humans are pretty amazing in our ability
to understand each other's muffled speech despite the
poor connection and background noise
much less the tinnitus and what have you.&lt;/p&gt;
&lt;p&gt;Nonetheless, I foresee a not too distant future where
it will be possible to cheaply attain human level accuracy
transcription of speaker-independent long-form speech
from noisy recordings obtained using mobile devices. Culminating in,
as &lt;a href="https://www.wired.com/2016/04/long-form-voice-transcription/"&gt;Wired's Jesse Jarnow&lt;/a&gt; puts it,
'bizarre kinds of unforeseen societal change'.&lt;/p&gt;
&lt;p&gt;Until then, court stenographers shouldn't have much to worry about.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;

&lt;script&gt;

var disqus_config = function () {
this.page.url = "https://pluteski.github.io/speech-to-text/"
this.page.identifier = "pluteski-github-io-speech-to-text"
};
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://pluteski-github-io-speech-to-text.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript"&gt;comments.&lt;/a&gt;&lt;/noscript&gt;

&lt;h6&gt;fin&lt;/h6&gt;</content></entry></feed>