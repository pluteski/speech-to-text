Title:  "A Cooperative Species" Distilled.
Subtitle:    Distillation of "A Cooperative Species, Human Reciprocity and Its Evolution" By Samuel Bowles & Herbert Gintis, 2011.
Project:     Life in Motion
Author:      Mark Plutowski
Affiliation: Economics in Motion
Web:         https://pluteski.github.io
Date:        2018-10-04


# Contents
This is a summarized version of the book 
**A Cooperative Species : Human Reciprocity and Its Evolution** 
By Samuel Bowles & Herbert Gintis, 2011. ([pdf](library.uniteddiversity.coop/Cooperatives/A_Cooperative_Species-Human_Reciprocity_and_Its_Evolution.pdf))

*Samuel Stebbins Bowles* is an American economist and Professor Emeritus at the University of Massachusetts Amherst, where he continues to teach courses on microeconomics and the theory of institutions.

*Herbert Gintis* continues to research econ & morality, and is also a frequent book reviewer on Amazon.com. 

This contains excerpts and paraphrased quotes from the book.  

**Caveats**

Some attempt is made to edit the excerpts and add paraphrasing to make this more readable.  However in some cases readability is sacrificed for fidelity. Most text that is not otherwise marked as an edit or editorial comment is an excerpt from the book -- however, you should confirm the quote yourself when using in a published account.  You should also quote the book, and not this summarized version.  

In almost all if not all cases, emphasis was added by the editor (yours truly). 

The book's authors claim that it is intended to be a scientific description of how human's behave in decision-making group settings, and not how they _should_ behave.  Likewise, if an excerpt is interpreted as a recommendation for how people _should_ behave, such an impression not intended.  This summary is intended to distill the book down to the essence of the author's claims, only, and not to emphasize or de-emphasize any claims except where they might detract from brevity -- such as in-depth details of experimental studies and formal proofs.

## Stats

* The 275 page book is distilled to 34 pages of excerpts. 
* Document statistics for the original book :
    - 275 of pdf formatted text
    - 202 pages of raw text
    - 120,458 words  
    - 770,779 bytes

* The summarized version has 34 pages 
    - 34 pages
    - 749   lines 
    - 10,475  words (8.7%)
    - 69,031 bytes (8.8%)

# Editor’s Summary
Why do humans, uniquely among animals, cooperate in large numbers to advance projects for the common good? Contrary to the conventional wisdom in biology and economics, this generous and civic-minded behavior is widespread and can not be explained simply by far-sighted self-interest or to desire to help close genealogical kin. 

In A Cooperative Species, Samuel Bowles and Herbert Gintis - pioneers in the new experimental and evolutionary science of human behavior - show that the central issue is not why selfish people act genetically, but instead how genetic and cultural evolution has produced a species in which substantial numbers make sacrifices to uphold ethical norms and to help even total strangers. 

The authors describe how, for thousands of generations, cooperation with fellow group members has been essential to survival. Groups that created institutions to protect the civic-minded from exploitation by the selfish flourished and prevailed in conflicts with less cooperative groups. Key to this process was the evolution of social emotions such as shame and guilt, and our capacity to internalize social norms so that acting ethically became a personal goal rather than simply to prudent way to avoid punishment. 

Using experimental, archaeological, genetic, and ethnographic data to calibrate models of the coevolution of genes and culture as well as prehistoric warfare and other forms of group competition, A Cooperative Species provides a compelling and novel account of how humans came to be moral and cooperative . Key to this process was the evolution of social emotions such as shame and guilt and our capacity to internalize social norms so that acting ethically became a personal goal rather than simply to prudent way to avoid punishment. 

# Summarized -- excerpts from the book
##Chapter 1 A Cooperative Species

reciprocal altruism (which really should be called “enlightened self-interest”) 

[non-cooperative] models fail to explain two facts about human cooperation: that it takes place in groups far larger than the immediate family, and that both in real life and in laboratory experiments, it occurs in interactions that are unlikely to be repeated, and where it is impossible to obtain reputational gains from cooperating.

we seek to explain why we are not purely selfish—why the social preferences that sustain altruistic cooperation are so common

In the course of our subsequent history we created novel social and physical environments exhibiting similar, or even greater, benefits of cooperation, among them the division of labor coordinated by market exchange and respect of rights of property, systems of production characterized by increasing returns to scale (irrigated agriculture, modern industry, information systems with network externalities), and warfare. The impressive scope of these modern forms of cooperation was facilitated by the emergence in the last seven millennia of governments capable of enforcing property rights and providing incentives for the self-interested to contribute to common projects.

prior to the emergence of governments and since, cooperation has been sustained also by motives that led some people to bear costs on behalf of others, contributing to common projects, punishing transgressors, and excluding outsiders. In the pages that follow we will advance three reasons why these altruistic social preferences supporting cooperation outcompeted unmitigated and amoral self-interest.

First, human groups have devised ways to protect their altruistic members from exploitation by the self-interested. Prominent among these is the public-spirited shunning, ostracism, and even execution of free-riders and others who violate cooperative norms. Other group activities protecting altruists from exploitation are leveling practices that limit hierarchy and inequality, including sharing food and information. 

Second, humans adopted prolonged and elaborate systems of socialization that led individuals to internalize the norms that induce cooperation, so that contributing to common projects and punishing defectors became objectives in their own right rather than constraints on behavior. Together, the internalization of norms and the protection of the altruists from exploitation served to offset, at least partially, the competitive handicaps born by those who were motivated to bear personal costs to benefit others. 

Third, between-group competition for resources and survival was and remains a decisive force in human evolutionary dynamics. Groups with many cooperative members tended to survive these challenges and to encroach upon the territory of the less cooperative groups, thereby both gaining reproductive advantages and proliferating cooperative behaviors through cultural transmission. The extraordinarily high stakes of intergroup competition and the contribution of altruistic cooperators to success in these contests meant that sacrifice on behalf of others, extending beyond the immediate family and even to virtual strangers, could proliferate. Modern-day nationalism is an example


Boundary-maintenance supported within-group cooperation and exchange by limiting group size and within-group linguistic, normative and other forms of heterogeneity. Insider favoritism also sustained the between-group conflicts and differences in behavior that made group competition a powerful evolutionary force


institutions proliferated because the groups that adopted them secured high levels of within-group cooperation


These capacities allow us to formulate general norms of social conduct, to erect social institutions regulating this conduct, to communicate these rules and what they entail in particular situations, to alert others to their violation and to organize coalitions to punish the violators. No less important is the psychological capacity to internalize norms, to experience such social emotions as shame and moral outrage, and to base group membership on such nonkin characteristics as ethnicity and language, which in turn facilitates costly conflicts among groups


the individual motives and group-level institutions that account for cooperation among humans include not only the most elevated, including a concern for others, fair-mindedness, and democratic accountability of leaders, but also the most wicked, such as vengeance, racism, religious bigotry, and hostility toward outsiders.

Price-fixing by cartels and other baleful economic effects of collusion motivated Adam Smith to advocate a competitive economic system under which such forms of antisocial collusion would unravel. In its stead he advocated “an invisible hand” that would guide the efforts of countless self-interested producers to coordinate a modern division of labor in the interest of all, a stunning example of mutualistic cooperation.

But if the late 18th century gave us this evocative metaphor for the beneficial effects of the pursuit of individual gain, the mid-20th century invented two no less riveting metaphors for the dark side of self-interest: the prisoner’s dilemma and the tragedy of the commons. Their logic inverted Adam Smith’s invisible hand, showing that even where cooperation was essential to the pursuit of common ends, it would falter in the face of self-interest

Social preferences, Hardin made clear, were powerless to counter the “remorseless” degradation of the environment: … “freedom in a commons means ruin for all,” 

Mancur Olson’s no less ineluctable “logic of collective action” in n-person prisoner’s dilemmas demonstrated the inevitability of a passive citizenry and the impossibility of cooperation, due to ubiquitous free-riders

Pyotr Kropotkin’s Mutual Aid a century earlier, a book that had advanced a kinder, gentler view of the evolutionary process in opposition to the then popular dog-eat-dog Social Darwinist claims about what natural selection entails for human behavior

[We] show that evolution can not only foster self-interest but also promote the generous and ethical behaviors that help us escape the prisoner’s dilemma and avert the tragedy of the commons

[We show] that this is true not despite, but in important measure because, evolutionary processes are “red in tooth and claw,” in Alfred, Lord Tennyson’s famous words.

## Chapter 2. The Evolution of Altruism in Humans
Americans. . . are fond of explaining almost all the actions of their lives by the principle of self-interest -- Alexis de Tocqueville, Democracy in America, 1835

modern game theory [is a] folk theorem [intending to explain how] close family members, repeated interactions and reputation-building might confer fitness advantages and other benefits on those engaging in seemingly unselfish behaviors. [emphasis added]

Our approach, however, favors Tocqueville, not Tocqueville’s Americans. Explaining why will take us through disciplines as diverse as population genetics, experimental economics, evolutionary game theory, and archaeology and across semantic minefields of heavily freighted terms, such as altruism, and controversial scientific questions, such as the relationship between genetic inheritance and cultural transmission.

###2.1 Preferences, Beliefs, and Constraints

We explore the proximal influences on an individual action such as helping using the **beliefs, preferences, and constraints** approach common to economics and decision theory. 

According to this approach, what individuals do when restricted to a specific set of feasible actions depends on their **desires** and **goals** on the one hand, and their **beliefs** on the other. 

The term **constraints** represent the limitations placed on the feasible actions an individual may take in a given situation. 

**Beliefs** are an individual’s representation of the causal structure of the world, including the relationship between the individual’s actions and the probabilities of the various possible resulting outcomes. 

**Preferences** are the pro or con sentiments that make up the individual’s valuation of the various possible outcomes of taking an action. Preferences may be described as an ordering (technically, a preference function) of the states of the world that may result from one’s actions.

We assume preferences satisfy two conditions: 
1. they are **complete** (any two states can be compared) and 
2. transitive; that is, **consistent**, so that if one prefers A to B and B to C, one then prefers A to C. 

Preferences are the results of a variety of influences: tastes (food likes and dislikes, for example), habits, emotions (such as shame or anger) and other visceral reactions (such as fear), the manner in which individuals construe situations (or more narrowly, the way they frame decisions), commitments (like promises), internalized norms of ethical behavior, psychological propensities (for aggression, extroversion and the like), and affective relationships with others.

We can succinctly and analytically summarize the individual’s behavior as maximization of a preference function.

To say that individuals act on their preferences means that knowledge of these preferences provides a concise and accurate account of their actions, given their beliefs and constraints . 

A version of the beliefs, preferences, and constraints model, incorporating the behavioral assumptions sometimes summarized as Homo economicus, has become standard not only in economics but throughout the human behavioral sciences. 

F. Y. Edgeworth, a founder of neoclassical economics, “*The first principle of economics is that every agent is actuated only by self interest*” (1881). 
Edgeworth followed the statement above with the caveat that the axiom was strictly true only in “contract and war.”

But self-interest need not be part of the preferences, beliefs, and constraints approach. Preferences could be altruistic or even masochistic.

**the self-interest axiom**: people seek to maximize their expected payoffs and believe that others do the same

The economist’s usual defense of the self-interest axiom is that it is self-evident, with the fallback assertion being that natural selection could not have produced any other kind of preferences. 

[They show that] the assertion is far from self-evident, and in fact is simply false.

###2.2 Social Preferences and Social Dilemmas
**social preferences** are a concern for the well-being of others and a desire to uphold ethical norms

**self-regarding preferences** … are based on states concerning oneself alone

**other-regarding** : as valuations based at least in part on states that occur to others

* An other-regarding player cares about not only his own payoff, but that of his partner as well

**Ethical commitments** may reflect a concern for the states experienced by others, but need not. 

* One can be honest because one seeks to avoid imposing costs on others by deceiving them. 
* But honesty could be entirely self-regarding, practiced in order to be the kind of person one wants to be. 
* Thus the textbook “economic man” would be described not only as **self-regarding**, but as **amoral** as well, 
* we use the simpler description — **self regarding** —when the meaning is clear.

**self-esteem** is dependent in part upon what others think of us, so we attempt to favorably impress others as a means of raising our subjective self-esteem

We prefer the term “**social preferences**” to the more common but ambiguous “unselfish” or “non-self-interested.” 

**social dilemmas** : interactions in which the uncoordinated actions of individuals result in an outcome that is Pareto inefficient, meaning that there exists some other feasible outcome such that at least one member could be better off while no member would be worse off. 

Examples of social dilemmas modeled by game theorists are 

* the prisoner’s dilemma, 
* the _public goods game_, sometimes termed an _n-person prisoner’s dilemma_, 
_war of attrition_ and other _arms race_ interactions, 
* the tragedy of the commons and the common pool resource game in which contributing to the common project takes the form of forgoing the overexploitation of a jointly utilized resource such as a fishery, water supply, or forest. 
We say a person _free rides_ if he benefits from the contributions of other group members while himself contributing less or nothing at all.


Social preferences … convert a prisoner’s dilemma material payoff structure into what is called an _assurance game payoff structure_ — each player will cooperate if assured that the other will cooperate as well, and will not if not. 
Thus mutual cooperation and mutual defection are both Nash equilibria. 
Which of the two Nash equilibria will obtain _depends on the players’ beliefs_ about what the other will do.

[Experiments definitively showed that] a majority of subjects (62%) were conditional altruistic cooperators.

 The same evidence shows that the fraction of most populations motivated solely by amoral self-regarding preferences is quite modest.

###2.3 Genes, Culture, Groups, and Institutions

According to gene-culture coevolution, human preferences and beliefs are the product of a dynamic whereby genes affect cultural evolution and culture affects genetic evolution, the two being tightly intertwined in the evolution of our species

##Chapter 3. Social Preferences

The self-interest axiom ... provides a clear prediction of how [a one-shot and anonymous] game will be played. However, when actually played, the predicted outcome is almost never observed and rarely even approximated.

[experiment subjects] are motivated by a desire to punish the proposer for being unfair, even though it means giving up some money to do so. While initially considered odd, these and other experimental results violating the self-interest axiom are now commonplace

###3.1 Strong Reciprocity Is Common

**strong reciprocity** [is when] people sacrifice their own payoffs in order to cooperate with others, to reward the cooperation of others, and to punish free-riding, even when they cannot expect to gain from acting this way 

* the term “strong” intended to distinguish this set of preferences from entirely amoral and self-regarding reciprocation that would not be undertaken in the absence of some payback. 

Because the strong reciprocator would increase his game payoffs by not cooperating, the motives for behaving this way are … altruistic 

###3.2 Free-Riders Undermine Cooperation
In a social dilemma that is repeated for a number of periods, subjects tend to start with a positive and significant level of cooperation, but unless there are very few free-riders in the group, cooperation subsequently decays to a very low level.


The experimental public goods game is ... an n-person prisoner’s dilemma [where] 

* the dominant strategy for a self-regarding player is to contribute nothing to the pool 
* in public goods experiments, only a fraction of subjects conform to the self-interest axiom


Part of the reason for the difference is that people have an intrinsic motivation to punish shirkers, 

* not simply an instrumental desire to alter [the shirkers’] behavior 
* or to affect the distribution of payoffs to either 
    * reduce unfairness 
    * or enhance one’s own relative payoffs

Consistent with …  “pure preference” motivation for punishment, subjects nonetheless punished shirkers, [meaning] that “agents enjoy punishment, where ‘enjoyment’ includes anger and a desire for retribution.” 

There is considerable further evidence for our non-strategic modeling of punishment 

* [here, “non-strategic” means that it would be considered non-rational according to neoclassical models based on non-cooperative game theory]

###3.4 Effective Punishment Depends on Legitimacy

public goods with punishment [experiments confirm] that altruistic punishment enhances cooperation [within] a group. 

But it raises a new question: do groups that punish free-riders actually benefit or do the costs of punishing outweigh the benefits to cooperation that result? [ answer : the former]

[However,] it is effective only if it is regarded as _legitimate_ according to widely held social norms. 

cultural differences [are] significant

in many societies a significant amount of punishment was directed at high contributors, possibly as a retaliation against punishment received in earlier rounds by subjects who believed that it was the high contributors who were doing most of the punishment

The result was vendetta-like retaliation against punishment leading to costly arms-race dynamics of wasteful punishment expenditures [called] “antisocial punishment.” 

the impact of antisocial punishment on average payoffs was very strong.


[ *ed. : if the crowd turns into a mob and rebels against the status quo by performing criminal acts, the outcome could be a short-term lowering of overall payoff, or it could be long-term, e.g., by helping a despot take over rule of the country, which could take years, decades, or generations to play out.**]

[ On the other hand, some types of punishment improve average payoffs ]
The time horizon effect: punishment raises average payoffs in the long run.

the determination of the punishment system by majority rule made the punishment not only an incentive but also a signal of group norms.

[ *(paraphrase):* if the population is allowed to vote on the means of punishment, it is a means for them to indicate what the social norms are, not what is necessarily ‘rational’ according to self-interest from a homo economicus perspective ]

punishment of group members is tuned to achieve legitimacy, is coordinated by gossip and rarely carried out by a single individual. 

making individual contributions publicly observable raises contributions to the public good substantially.

free-riding elicits extremely strong negative emotions among the other group members

**dictator game**: Alice gives a certain amount of money to Bob, who has no say in the matter. 

**third-party punishment game**: variant on the dictator game in which that Carole, the “third party,” has an endowment of 50 tokens and observes Alice’s transfer. After this Carole can assign punishment points to Alice. Each punishment point assigned to Alice costs Carole one token and Alice incurs a penalty of three tokens. Because punishment is costly, a self-regarding Carole will never punish. However, if there is a sharing norm, Carole may well punish Alice if she gives too little.

**Indirect reciprocity**: occurs when Carole is likely to punish Alice when Alice has been unfair to Bob, and is likely to reward Alice when Alice has been nice to Bob. 

**Strategic reputation-building**: occurs when Carole behaves in the above manner only when her actions are seen by others, and hence can help build a reputation for social behavior

unless there are indirect reciprocators, strategic reputation-building can have no effect.  Nevertheless … even self-regarding individuals may engage in third-party punishment if they believe that this will induce other-regarding individuals to behave favorably toward them.

Punishment is thus not simply retaliation in response to personal damages but appears to reflect more general ethical norms


###3.7 Social Preferences Are Not Irrational

The term “**rationality**” [is] misused as a synonym for “consistent pursuit of self interest.”
[in actuality] subjects [are] no less rational when deciding to cooperate and punish than when they compare prices to decide what to cook for dinner. 
the preferences that lie behind their social behavior are consistent with the basic axioms of rationality, namely on transitivity (i.e., _consistency_) and _completeness_.

for many [people] virtue is its own reward 

* This is perfectly consistent with the fact that, as in the case of people with self-regarding preferences, they would consider the price.
* [ if you include the proper factors into the equation, otherwise ‘irrational’ behavior is actually rational ]

###3.8 Culture and Institutions Matter 
experimental evidence accumulated in the 1990’s showing that many, perhaps most, individuals are not entirely self-regarding

Could Homo economicus simply be replaced by Homo sociologicus, Homo altruisticus, or, as we once suggested, Homo reciprocans?

we doubt that such a universal model will prove viable [because] institutions serve as cues for appropriate behaviors

E.g., competitive gift giving as a means of establishing status and subordinacy in [many] New Guinea societies

[Again, in experiments examining culture effects] not a single group approximated the behaviors implied by the self-interest axiom

where voluntary public goods provision was customary in real life [behavior in the experiment mirrored the real life system]. [For example, among Orma herders in Kenya those having more contributed more.] 

By contrast, in the ultimatum game, for which there apparently was no everyday life analogue, the wealthy behaved like the other Orma [ meaning they did not seem to be influenced by culture or institution, instead behaving according to more deeply rooted norms].

###3.9 Behavior Is Conditioned on Group Membership

1. Those who condition their behavior on the group membership of the other may do this because group membership is thought to provide information about the other’s likely behavior. 
2. [Or perhaps instead,] group membership may matter because people would like to help or to interact with members of some groups more than others. 

* In the first case the actor’s beliefs are involved. 
* In the second case, group-sensitive preferences are at work. 

Group-sensitive preferences may be **other-regarding** (valuing the well-being of members of one’s own group, for example) or **self-regarding**  (e.g. experiencing anxiety in culturally unfamiliar interactions).

[some experiments showed that] subjects’ allocations favor in-group members not because of altruistic sentiments toward those who are similar to themselves, but because they expected reciprocation from in-groupers and not from out-groupers.

**trust game** : Alice is awarded a sum of money and given the opportunity to transfer any amount of it to Bob, knowing that the experimenter will triple the amount transferred (if Alice gives x, Bob receives 3x). Bob then has the opportunity to return some of this augmented sum to Alice. This ends the game. Alice is sometimes called the “truster” or “investor,” and Bob the “trustee.”

[it turns out that] taking account of ethnic, racial and other characteristics of those with whom one interacts appears to be a quite common human trait

We find no evidence for a commonality of tastes within ethnic groups, or greater degrees of altruism toward coethnics or for an impact of shared ethnicity on the productivity of teams. [Rather]. . . successful collective action among homogeneous ethnic communities. . .is attributable to the existence of norms and institutions that facilitate the sanctioning of non-contributors. 

* here, ethnicity does appear to matter. 
* Norms may dictate ethnic favoritism, 
* and in public settings subjects may fear sanctions were they to not respect these ethnic norms. 
* Remarkably, ethnic favoritism, which was absent in an anonymous dictator game, was evident among some subjects when the dictator’s identity was public information.


###3.10 People Enjoy Cooperating and Punishing Free-Riders

[results from] ultimatum game, public goods game, and other social dilemma experiments is that 

* people think that cooperating is the right thing to do and enjoy doing it, and 
* that they dislike unfair treatment and 
* enjoy punishing those who violate norms of fairness

####[On neuroeconomics](https://en.wikipedia.org/wiki/Neuroeconomics) :

* Recent studies of brain functioning provide some support for this hedonic view of cooperative behavior. 
* Using positron emission tomography (PET), fMRI, and other techniques, neuroscientists, economists and others have begun to study the activation of the different brain areas of subjects playing experimental games
* ultimatum game responders who reject a low offer exhibit heightened activation of the bilateral anterior insula, an area associated with negative emotional states such as anger and disgust. “It is irresistible to speculate that the insula is a neural locus of the distaste for inequality and unfair treatment.”
* mutual cooperation with a human partner produces a higher level of striatum activation than does cooperation with a computer partner

The above studies do not suggest that cooperating and punishing defectors is innate. 

* Some foods that evoke disgust in one culture are delicacies in others. 
* Cross-cultural experimental evidence is consistent with the view that behaviors in social interactions that trigger aversive reactions likewise vary from one society to another

## Chapter 4. The Sociobiology of Human Cooperation
>>    “I shall argue that a predominant quality to be expected in a successful 
>>    gene is ruthless selfishness. This gene for selfishness will usually 
>>    give rise to selfishness in individual behavior.” -- Richard Dawkins, 
>>    The Selfish Gene (1976)

“Selfish and contentious people will not cohere, and without coherence, nothing can be effected. … social and moral qualities would tend … be diffused throughout the world. Charles Darwin, The Descent of Man (1873)

[ ed. _something tells me that they agree with Darwin_ ]

Several advances occurred:

* The central importance of social structure [was convincingly argued by] Edward O. Wilson in his massively influential The Insect Societies (1971) and Sociobiology: The New Synthesis (1975)
* 1970, George Price provided an ingenious method for the analysis of selection processes operating at multiple levels, providing a way to study the evolution of social behavior in group-structured populations [ this shows how behaviors can emerge at a group level that are not evident at the lower level -- even though genes are selfish, groups can behave altruistically ] 
This is known as “multi-level selection”
* Cavalli-Sforza and Feldman published “Cultural versus Biological Inheritance” (1973a), [arguing for] **gene-culture coevolution**
* in 1973, John Maynard Smith and Price published “The Logic of Animal Conflict”
    * This paper launched the field of evolutionary game theory

multi-level selection may be of considerably greater importance among humans than among other animals given the 
* advanced level of human cognitive and linguistic capabilities and 
* consequent capacity to maintain group boundaries and 
* to formulate general rules of behavior for large groups, and 
* the resulting substantial influence of cultural inheritance on human behavior 

Among the consequences of these distinctive human capacities are the suppression of within-group phenotypic differences through egalitarianism, coinsurance, consensus decision making and conformist cultural transmission. 

Other animals do some of these things, but none does all of them on a human scale. 
* All of these aspects of human social life enhance the force of between-group selection relative to within-group selection. 
* A result, if we are correct, was the evolution this cooperative species. 

### Competing alternative explanations
A rather different interpretation of human altruism and its evolution is that, on closer inspection, most apparently altruistic forms of helping are just self-interest with a long time horizon. 

This approach takes **reciprocal altruism** as its starting point and shows how, when interactions are _frequently repeated_, individuals may enhance their fitness by a **mutualistic** form of helping based on _the expectation of reciprocation in the future_. 

Variants of this approach developed in models of **indirect reciprocity** and **costly signaling** show that _helping others may be repaid not only by the targets of one’s help_ but also by _others wishing preferentially to be associated with the helpful_.

Competing models explaining cooperation in human society :

1. Inclusive Fitness -- 1930, 1964
    * Kin-based Altruism -- 1964 
    * Group-based Altruism (multi-level selection) -- 1977 , 1982,  1990 
    * Network-based Altruism  -- 2006 
2. Reciprocal Altruism & Mutualism -- 1971 
    * Signaling Reputation -- 1973 , 1990 , 1975 
    * Indirect Reciprocity -- 1987 , 1986 
    * Repeated Games Folk Theorem -- 1981 , 1986 

[ An important parameter in these models is what economists term the rate of time preference ]

[For example ] : reciprocal altruism can piggyback on kin-based altruism to get started

[ It may be that humans are able to mentally simulate the future better, or, have a longer time preference parameter, because ] non-human animals are extraordinarily impatient. Behaviors that at first appeared to be reciprocal have frequently, on further study, been better explained as **simple mutualism** in which the benefit to the actor compensates for the cost of the action regardless of the action taken by the other.

### 4.5 Reciprocal Altruism in Large Groups

To illustrate the consequences of extending the reciprocal altruism model to groups larger than two, we will develop an **agent-based model**.  A large population consists of N groups of n members each, and each group plays a public goods game repeatedly d times. We will call this series of d rounds an **encounter**. 

### 4.6 Reputation: Indirect Reciprocity
[ here they steel man a competing theory ]

The **standing model** 

* An alternative mechanism of cooperation [where] individuals [remember] who cooperated with their partners in the previous period and those who did not. 
* an individual who cooperated in the previous period [is considered to be] “in good standing”, 
* the only way an individual can fall into bad standing is by defecting on a partner who is in good standing. 
* Thus, an individual can always defect when his partner is in bad standing without losing his good standing status. 
* the “standing strategy” is : cooperate if and only if your current partner is in good standing, except that if you accidentally defected the previous period, cooperate in this period unconditionally, thereby restoring your status as a member in good standing. 

**Indirect reciprocity** and **signaling models** are similar in that the payback for the individual’s cooperative action comes from third parties.

The two models differ in a subtle way: 

1. in the signaling model the third party responds favorably because the signal is correlated with some desirable but unobservable property of the actor; 
2. in the indirect reciprocity model the signal (cooperating with those in good standing) is the desirable property itself. 

In the case of indirect reciprocity, I want to associate with the hunter who shares his ample prey with other members of the group because I too would like a share of meat. 

In the signaling model I want to associate with him because the fact that he has lots of meat to share indicates that he is physically able and would be a good mate or coalition partner. [ it is correlated with some other desirable quality ]

## Chapter 5. Cooperative Homo economicus
[ in this chapter they argue that the level of cooperation is impossible to model with only noncooperative game theory ]

a major goal of economic theory since its inception two and a half centuries ago has been to explain the mutual benefits provided by a widespread form of voluntary cooperation, market exchange among self-regarding individuals. 

This endeavor culminated half a century ago in the fundamental theorem of welfare economics (Arrow and Debreu 1954, Debreu 1959, Arrow and Hahn 1971), sustaining Smith’s insight that self-regarding behaviors might support socially valued economic outcomes. 

In the resulting model of exchange, individuals maximize their utility given a set of market-determined prices over which they exercise no control. They thus interact with a list of prices, not with one another. 

As a result the essential condition for strategic behavior, recognition that the payoffs of each depend on the actions of others is absent. The reason that individuals are content to interact through prices alone, and hence have no incentive to engage in strategic personal interactions, is that all relevant aspects of exchanges are assumed to be covered by complete contracts, enforceable at no cost to the exchanging party. 

A complete contract ensures that any aspect of an exchange in which the parties have an interest will be explicitly stated in the contract and implemented as specified. The enforcement of the contract in case of breach is entrusted to a third party, generally the courts, and is assumed to impose no costs on the injured party

[ they go on to argue that complete contracts are practically impossible without institutions, and even with institutions are largely ineffective  

even presupposing extraordinary cognitive capacities and levels of patience among the cooperating individuals, there is no reason to believe that a group of more than two individuals would ever discover the cooperative Nash equilibria that the models have identified, and if it were to hit on one, its members would almost certainly abandon it in short order. Except under implausible conditions, the cooperative outcomes identified by these models are neither accessible nor persistent. We term them evolutionarily irrelevant Nash equilibria.


### 5.1 Folk Theorems and Evolutionary Dynamics

All folk theorems are based on a stage game, that is, an interaction played an indefinite number of times, with a constant, strictly positive, probability that in each period the game will continue for an additional period 

A strategy in this game that dictates following one course of action until a certain condition is met and then following a different strategy for the rest of the game is called a trigger strategy

[ it turns out that the existence of trigger strategies is an achilles heal for folk theorem models ] 
it is [extremely difficult to] come to a working arrangement among … many independent spirits, in the absence of a regulating social institution to which all are committed. 

the n-player reciprocal altruism model can sustain a high level of cooperation only in very small groups

[Apparently] directed punishment appears to solve the problem of cooperation in large groups. There is a catch, however. Because punishing costs the punisher, self-regarding players have no incentive to carry out the punishment. Thus, this model does not work assuming self-regarding players. We have seen in Chapter 3 that people avidly punish defectors even at a cost to themselves, providing a solution to this problem, but one that is based on social preferences rather than self-interest. 

this coordination problem is [largely because] the information each has on the others’ actions is subject to error. 

### 5.3 The Folk Theorem with Private Information

[ The problem gets even worse with private information.  To summarize, the only way the alternative theory based on self-regarding homo economicus can work is if all information is public and all agents are omniscient ]

There is another approach to constructing Nash equilibria for repeated games with private signals [ that actually DOES work, but where ] players use strictly mixed strategies (that is, they randomize over various actions rather than taking a single action) in each period.

[ They claim that human players cannot or will not ever actually use such mixed strategies.  -- However, it turns out that AI agents could -- meaning if the agents are algorithms then coordination is possible even where information is private, by AI using mixed strategies. ]

A mixed strategy for a player is a probabilistic combination of pure strategies, such as playing heads or tails each with 50% probability in a pennies-matching game. 

### 5.4 Evolutionarily Irrelevant Equilibria 
The folk theorem provides no reason to believe that players would ever coordinate [and] should this occur by chance the equilibrium would [not last very long]. 

It is plausible that individuals are [able to coordinate] given full knowledge of the game and the choices of the other players. But when knowledge is imperfect or private and the choices of the other players are not known [i.e., other agents are not omniscient mind-readers then folk theorems fail and fail miserably ].

[It turns out that we now know that] Nash equilibrium are [extremely difficult to find and maintain] except in the simplest of cases (1995). 

* The problem with achieving a Nash equilibrium is that individuals may have heterogeneous and incompatible beliefs concerning how other players will behave, 
* and indeed what other players believe concerning one’s own behavior. 
* Therefore, individuals may choose best responses to strategies that the other players in fact are not playing, resulting in game play that is far from any Nash equilibrium. 
* the conditions required for players to implement a Nash equilibrium in all but the simplest games cannot be deduced from the assumption that the players are rational [in the neoclassical sense] i.e., that they choose best responses.

Fatal flaws of the folk theorem (classical econ) approach:

1. If there is a Nash equilibrium with private signals, individuals have no particular incentive to play the strategies that implement the equilibrium, because 
2. many other strategies have the same payoffs as the equilibrium payoffs. 
3. Moreover, as we have seen, the equilibrium exists only if private signals are very close to being public, so all individuals receive nearly the same signal concerning the behavior of any given group member. 
4. When this is not the case, the equilibrium will not exist. 
5. Thus, these models apply only to forms of cooperation where all members observe the actions of (nearly) all others with a high level of accuracy.

[ _In other words, the classical econ theories only work with inhuman players_ ]

### 5.5 Social Norms and Correlated Equilibria 

There is an alternative game-theoretic equilibrium concept that does not share the weaknesses associated with the Nash equilibrium described above: the correlated equilibrium [with a correlating device].

A correlating device is something that sends out signals, private or public, to the players of a game, indicating which pure strategy each should play. 

A correlated equilibrium is a situation in which there is a correlating device such that, if all players follow the advice of the correlating device, no player can do better by switching to an alternative strategy.

correlated equilibrium rather than Nash equilibrium is the appropriate equilibrium concept for game theory. 

* Assuming players have common knowledge of the game, its rules, and its payoffs, as well as a common belief concerning the probability of the natural events (the so-called moves by Nature) associated with the game, the strategies chosen by rational individuals can then always be modeled as a correlated equilibrium with an appropriate correlating device. 
* The notion of a correlating device is quite abstract, but one form of correlating device is well known and performs precisely the social function of signaling actions to individuals that, when followed, may lead to a socially efficient outcome. This device is the social norm which, like the choreographer in a ballet, is instituted to issue precise instructions that, when followed, produce the desired outcome. 
* For instance, the system of traffic lights in a city’s street network instruct drivers when to stop and when to go, and it is normally in the interest of drivers to obey these signals as long as others do so, to avoid accidents. [ i.e., drivers obey a social norm ]

A cooperative equilibrium supported by social norms is one in which not only is the equilibrium strategy evolutionarily stable, but also the social norms are themselves an evolutionary adaptation, stable against invasion by competing social norms

we posit that groups have social norms specifying how a game ought to be played and that these norms are identified as social norms by group members

Social norms do not ensure equilibrium, because error, mutation,migration, deliberate violation of the norm, and other dynamical forces may lead individuals to reject beliefs or behavior fostered by the norm. 

* This may occur because the beliefs might conflict with an individual’s personal experience, 
* or its suggested behavior may be rejected as not in the individual’s best interest; 
    * i.e., the action fostered by a social norm must be a best response to the behaviors of the other group members, given the beliefs engendered by the social norm and the individual’s updating. 
* Moreover, social norms cannot be introduced as a deus ex machina, as if laid down by a centralized authority, without violating the objective to provide a “bottom-up” theory of cooperation that does not presuppose preexisting institutional forms of cooperation. 
* Social norm are thus discretionary, because any institution that is posited to enforce behavior should itself be modeled within the dynamical system, unless plausible reasons are given for taking a macro-level institution as unproblematically given. 
* Nor are social norms fixed in stone. A group’s social norms are themselves subject to change, those groups producing better outcomes for their members sometimes but not always displacing groups with less effective social norms, and changing social and demographic conditions leading to the evolutionary transformation of social norms within groups

### 5.6 The Missing Choreographer

[The] celebrated **fundamental** (“_invisible hand_”) **theorem of welfare economics** ... purports to model decentralized market interactions, but on close inspection requires an extraordinary level of coordination that is not explained, but rather is posited as a deus ex machina.

Humans are ... exceptional among living creatures in the degree and range of cooperation among large numbers of substantially unrelated individuals. 

* The global division of labor and exchange, the modern democratic welfare state, and contemporary warfare alike evidence our distinctiveness. 
* These forms of cooperation emerged historically and are today sustained as a result of the interplay of self-regarding and social preferences operating under the influence of group-level institutions of governance and socialization that favor cooperators, 
* in part by helping to coordinate their actions so as to target transgressions for punishment and thus protect them from exploitation by defectors.

The norms and institutions that have accomplished this evolved over millennia through trial and error

the private nature of information, as we have seen, makes it virtually impossible to coordinate the targeted punishment of miscreants

In many hunter-gatherer societies the relevant information that would in other societies be private is rendered public by such cooperative customs as eating in public so that violations of sharing norms can be easily detected. Cooperative Japanese shrimp fishermen who pool income across boats deliberately land their catch at an appointed time of day for the same reason 

 But in most modern societies, where larger numbers are involved, converting private information about transgressions to public information that can provide the basis of punishment often involves civil or criminal trials, elaborate processes that have evolved over centuries and that rely on commonly agreed upon rules of evidence and ethical norms of appropriate behavior. Even with the benefit of these preexisting social preferences, these complex institutions frequently fail to transform the private protestations of innocence and guilt into common knowledge

Second, ... cooperation often unravels when the withdrawal of cooperation by the civic-minded intending to punish a defector is mistaken by others as itself a violation of a cooperative norm, inviting a spiral of further defections. 

* In virtually all surviving societies with substantial populations, this problem is addressed by the creation of a corps of specialists entrusted with carrying out the more severe of society’s punishments. 
* Their uniforms convey the civic purpose of the punishments they mete out, 
* their professional norms, it is hoped, ensure that the power to punish is not used for personal gain. 
Like court proceedings, these policing, penal, and related institutions work imperfectly


##### Capsule summary of the book
[ This serves as a decent capsule summary of the book ]

>> Modeling the complex processes that sustain human cooperation is a major 
>> challenge of contemporary science. Economic theory, favoring parsimony over 
>> realism, has sought to explain cooperation without reference to social 
>> preferences, and with a minimalist or fictive description of social 
>> institutions. This research trajectory, as we have seen, has produced 
>> significant insights. But it may have run its course.


## Chapter 6. Ancestral Human Society

[ on how cooperation got bootstrapped in ancient times ]

## Chapter 7. The Coevolution of Institutions and Behaviors
**reproductive leveling** contributes to the evolution of altruism. 

Individual differences in size, health, information, behavior, and other influences on access to scarce resources [affect] reproductive success. 

Among some other primates and especially among humans, reproductive leveling attenuates this relationship. Because altruists receive lower payoffs than other group members, they benefit from reproductive leveling because this attenuates the within-group selective pressures working against them

## Chapter 8. Parochialism, Altruism, and War
by **parochialism** they mean religious intolerance, racism, xenophobia, which vary across cultures and over time.

The fact that altruism and parochialism may have a common evolutionary origin, whether cultural or genetic, does not mean that the two are inseparable. Examples of tolerant, even anti-parochial, altruism include subjects in some intergroup behavioral experiments, the electoral support in many countries for tax-supported economic aid to the people of poor nations, and the participation of people of all ancestral groups in political movements against racism.

## Chapter 9. The Evolution of Strong Reciprocity
a _predisposition to cooperate and a willingness to punish defectors_ is what we have termed **strong reciprocity**, and it is the combination of the two that is essential to the large-scale cooperation exhibited by our species

Punishment reduces the gain to free-riding, and induces self-interested individuals to cooperate


### 9.1 Coordinated Punishment 
##### Summary
[ *Previously it was argued that punishment improves group effectiveness, and that centralized punishment over large groups is a recent cultural evolution and still quite ineffective.  This section shows how decentralized punishment works.* ]

[ Outline of the model ]
The initial period in the life of a group has three stages. 

1. a signaling stage in which at cost q, punishers can signal their intent to punish any defector. The cost of signaling is high enough that it does not pay to signal and then not to punish. 
2. a cooperation stage, during which individuals can choose to cooperate or defect. Cooperation costs the cooperator c and benefits each member of the group b=n. As usual, we assume b > c > b=n. _Were there no punishment option, the interaction would be a public goods game (n-person prisoners’ dilemma) in which the dominant strategy would be to not cooperate_. [ which is both why punishment is necessary and cooperative game theory + correlated equilibrium are good explanations, because people DO cooperate, but WOULD NOT if not for punishment along with a correlating device (our norms) ]
3. a punishment stage in which individuals can coordinate with other punishers to administer punishment.

“**second-order free-rider**” problem : individuals who cooperate but do not punish outcompete the Punishers. [ *there must be enough Punishers in the group to tolerate Cooperative Nonpunishers* ]

### 9.2 Altruistic Punishment in a Realistic Demography 
[ Computer simulations ]

### 9.3 The Emergence of Strong Reciprocity 
[ Computer simulations … showing why “Opportunists” ruin a group ]

### 9.4 Why Coordinated Punishment Succeeds 
[ why Punishers prevail in terms of the signals operated on by darwinian selection ]

### 9.5 A Decentralized Social Order
[ ed. - *mentions Cosmides and Tooby (1992), Evolutionary Psychologists* ]

While size, strength, and vigor generally determine the outcome of animal disputes, victory often involving great cost even to the winner, in human societies, through the use of coordination, stealth and deadly weapons, even a small number of attackers can defeat the most formidable single enemy at very low fitness cost to the attackers.

[ _humans are excellent at clubbing and throwing projectile weapons compared to other animals_ ]

[ They criticize the the “folk theorem” as relying on ] fictive Rube Goldberg strategies.

[ ed. - _here is why non-cooperative game theory works so hard at ensuring the truthful operation of participants:_ ] 

**(a)** self-interested … members will typically have something to gain by misrepresenting the actions taken by others **(b)** [ mistakes happen, and with classical game theory this causes the group to spiral into anarchy ]

Modern large-scale societies, we observed, convert private to public information by judicial processes that took centuries to evolve and that presuppose that court officials, jury members, and law enforcement officers adhere to standards of professional conduct that preclude the unrestrained pursuit of self-interest.

Smaller scale ancestral groups devised other ways to convert private to public information. Gossip, group discussions with all or most members present, and taking meals in public are examples.

[ for larger groups, a decentralized approach is required, and an internalized correlating device ]

individuals who developed the capacity to internalize group-beneficial norms and to feel chastened when punished for violating these norms [and] groups that devote their socialization practices to this end [would thrive]. 


## Chapter 10. Socialization
Conformist cultural transmission may arise for a variety of reasons, ranging from an evolved social learning strategy in which individuals regard the population frequency of a trait as a measure of its desirability, all the way to population-level institutional arrangements for the deliberate socialization of the young, in which the content reflects which types are prevalent in the population. We stress the latter for empirical reasons: most societies devote substantial time and resources to deliberately socializing the young to act in ways that are beneficial to others, and an adequate explanation of social preferences needs to take account of this fact

[ at some point along the way, cultural learning results in effective norms, and eventually these norms are internalized, either by socialization, or for certain powerful norms, genetically resulting in ] Gene-Culture Coevolution

a considerable fraction of the total available time of the members of most societies is spent teaching the young the proper way to behave, rather than providing for the nutritional and other needs of its members. But in addition to the cost of acquiring such a norm (u>0), there is a further cost: the rule will not be ideally suited to all situations, and its internalization deprives the individual of flexibility in dealing with such situations on a case-by-case basis

Why, then, are humans so susceptible to internalizing general rules? because it relieves the individual from calculating the costs and benefits in each situation and reduces the likelihood of making costly errors. [ precomputing frequently needed results for rapid access … similarly as with other more primary emotional reasoning ]

A similar argument led John Stuart Mill to remark, “Being rational creatures [sailors] go to sea with it [the Nautical Almanac] already calculated; and all rational creatures go out upon the sea of life with their minds made up on the common questions of right and wrong, as well as on many of the far more difficult questions of wise and foolish”


## Chapter 11. Social Emotions

individuals maximize a utility function that includes five distinct motives: 

1. one’s individual material payoffs, 
2. how much one values the payoffs to others, 
3. this depending on both one’s unconditional altruism 
4. and one’s degree of reciprocity, as well as 
5. one’s sense of guilt or shame in response to one’s own and others’ actions.

punishment [serves the following purposes] : 

* [it] not only reduces material payoffs of those who transgress norms, 
* but also may recruit emotions of shame toward the modification of behavior. 

in some societies many defectors react to being punished by increasing their contribution to the group, even when the punishment does not affect material payoffs, consistent with the shame response, 

in other societies [the punished] react by counterpunishing contributors, consistent with an anger response. 

Social emotions in response to sanctions can thus either foster or undermine cooperation. 

Reacting to sanctions, then, is often not a dispassionate calculation of material costs and benefits, but rather involves the deployment of culturally specific social emotions. 

the altruistic punishment of shirkers by strong reciprocators can proliferate in a population and sustain high levels of cooperation, 

social emotions and punishment of miscreants may be synergistic, each enhancing the effects of the other.

## Chapter 12 Conclusion: Human Cooperation and Its Evolution

>> “Any animal whatever, endowed with well-marked social instincts, the
>> parental and filial affections being here included, would inevitably 
>> acquire a moral sense or conscience, as soon as its intellectual powers had 
>> become as well developed, or nearly as well developed, as in man.” -- 
>> Charles Darwin, The Descent of Man Chapter IV (1873)

[ How did it get started? Some small tweak to ]

* kin-based altruism, [which resulted in] ceased discriminating against the non-kin members 
* reciprocal altruism [which resulted in] deleting the proviso that one should condition one’s behavior on expectations of future reciprocation

[these traits evolved ] over tens of thousands of generations and something like 150,000 foraging bands

1. models and simulations of our evolutionary past ... provide strong evidence that … the group structured nature of human populations could have been a significant influence on human evolution. 
2. we have also demonstrated the important contribution to the evolution of social preferences that could have been accomplished by the cultural transmission of empirically well-documented behaviors such as the 

    * internalization of norms, 
    * within-group leveling, and 
    * between-group hostility. 

3. preferences revealed in behavioral experiments and in other observations of human behavior is consistent with the view that genuine altruism provides the proximate explanation of much of human cooperation. [this means]

    - a willingness to sacrifice one’s own interest to help others, 
    - including those who are not family members, 
    - and not simply in return for anticipated reciprocation in the future


The challenge of explaining the origins of human cooperation has

* Led us to study social and environmental conditions of life of mobile foraging bands and other stateless small-scale societies that arguably made up most of human society for most of the history of anatomically modern humans. 
* Made noncooperative game theory (which assumes the absence of enforceable contracts) an essential tool. 

But ... most forms of contemporary cooperation are supported by incentives and sanctions based on a mixture of multilateral peer interactions and third-party enforcement, often accomplished by the modern nation-state.

**It would thus be wise to resist drawing strong conclusions about cooperation in the 21st century solely on the basis of our thinking about the origins of cooperation in the Late Pleistocene.** [emphasis added]

But the fundamental challenges of social living and sustaining a livelihood that our distant ancestors faced are in many respects not fundamentally different from those we face today. Modern states and global markets have provided conditions for mutualistic cooperation among strangers on a massive scale. 

altruistic cooperation remains an essential requirement of economic and social life

The reason is that neither private contract or governmental fiat singly or in combination provides an adequate basis for the governance of modern societies. 

* Social interactions in modern economies are typically at best quasi-contractual. 
* Some aspects of what is being transacted are regulated by complete and readily enforceable contracts, while others are not. 
* Transactions concerning credit, employment, information, and goods and services where quality is difficult to monitor provide examples of quasi-contractual exchanges. 
* Where contracting is absent or incomplete, the logic of Adam Smith’s invisible hand no longer holds. 
* Decentralized markets fail to implement efficient allocations. 
* governments typically lack the information, and often the motivation, necessary to provide adequate governance where markets fail or are absent

We now know from laboratory experiments that subjects in marketlike situations with complete contracts tend to behave like the Homo economicus of the Adam Smith of The Wealth of Nations, but when their contracts are not complete their behavior fortunately resembles more the virtuous citizens of the Adam Smith of The Theory of Moral Sentiments. 

[*a quotable nutshell summary of much of this book:*]

**Thus, where the invisible hand fails, the handshake may succeed**


social preferences such as a concern for the well-being of others and for fair procedures remain essential to sustaining society and enhancing the quality of life

[ Closing: ]

In a world increasingly connected not just by trade in goods but also by the exchange of violence, information, viruses, and emissions, the importance of social preferences in underwriting human cooperation, even survival, may now be greater even than it was among that small group of foragers that began the exodus from Africa 55,000 years ago to spread this particular cooperative species to the far corners of the world.


# Appendix : definitions

### Agent-based modeling 
is a tool for analyzing complex dynamical systems as a complement to explicit mathematical analysis where the latter is either impossible or uninformative. 

* In these models, the actors are individual agents who share many characteristics, but differ on key characteristics that affect their relative reproductive success, material payoffs or other results that affect the differential replication of distinct types of individuals. 
* The agents operate semi-autonomously, but are linked through a network of structured interactions. 
* The individual characteristics in a complex system evolve through a process of replication, mutation, and finally selection that favors relatively successful individuals. 
* Such dynamics are recursive, 
    * meaning that changes in one period become the basis for changes in future periods, 
* and are non-linear, 
    * which implies that forces propagate through the system in an uneven and variably dampened or amplified manner, 
    * with the implication that they are generally incapable of being expressed as closed-form analytical solutions to sets of equations.

Such modeling (often called “**simulation**”) lies outside the two standard methods of gaining scientific knowledge: **deduction** and **induction**. 

* **Deduction** means proving theorems, that is, showing that certain mathematical conclusions follow from certain axioms 
* **Induction** means finding lots of evidence and drawing conclusions 

**Agent-based modeling** is like deduction in that it starts with a rigorously specified computer program, but it is like induction in that it treats the operation of the program as a set of data points from which generalizations can be made. 

if a complex system has emergent properties, these can be ascertained by implementing an agent based model in which these properties are seen and persist over many simulations. 

How do we judge the empirical adequacy of an agent-based model? 

1. one can ensure that the parameters chosen are empirically plausible for the populations under study. 
    1. check how much difference variations in the parameters make for the results of the simulation, as we have done in many cases. 
    1. On the basis of this sensitivity analysis we then spend special attention making sure that the parameters that matter are well estimated. 
2. exploit the fact that while the processes under investigation are unknown (that is why we are simulating them), 
    1. the simulations generate a large number of by-product statistics on aspects of the relevant populations on which we do have some knowledge. 
    1. Thus we can ask whether the results of the simulation conform to known facts about the populations under study. [ meaning, they have some predictive appeal -- the hypothesis is that their data will match that of the real system in 2nd and 3rd order effects not just the immediate ]
    1. where the models have generated implausible by-product statistics, diagnose the source of the problem and recalibrate 


<center><bold>Figure A1: Structure of evolutionary game-based simulation</bold></center>
<center>
<img src="http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/cooperative_species/cooperative_game_params.png" width="400" height="600" />
</center>






<center><bold>Figure A2: Structure of replication process.</center></bold>
<center>
![Figure A2: Structure of replication process.](http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/cooperative_species/a2_replication_process.png)
</center>




# A3 Game Theory
Game theory is a mathematical tool for the study of **strategic** interactions [where] payoffs of individuals depend on their own actions and the actions taken by others. 

[ a player's **strategy** is any of the options he or she can choose in a setting where the outcome depends not only on their own actions but on the action of others.]

[ A **pure strategy** determines all your moves during the game (and should therefore specify your moves for all possible other players' moves). A **mixed strategy** is a probability distribution over all possible **pure strategies** (some of which may get zero weight) ] 


[**a state is a ] Nash equilibrium** : if every player’s choice is a best response to the choices of the other players [ _which are supposed to be public, and known to and understood by every other player_ ]

a dominant strategy offers a higher payoff than any other strategy, no matter what the other players do. 

A stage game of the repeated game is repeated indefinitely, with a positive probability of terminating the process at the end of each period 

The most important fact about the repeated game based on stage game G is that it can support cooperative equilibria in situations where G cannot.

The **evolutionary game models** [used] in this book are distinct from **classical game theory**. 

_The key idea in evolutionary game theory is differential replication rather than best response._ 

**adaptive agents** in evolutionary games adopt behaviors in a manner similar to the way people come to have a particular accent or to speak a particular language. 

Forward-looking payoff-based calculation is not entirely absent (e.g., those aspiring to upward mobility may adopt upper class accents) but conscious optimizing is not the whole story. 

The answer to “why do you talk like that?” is generally: “because I was born where people talk like that” not “because I considered all the ways of speaking and decided that speaking this way best serves my personal goals.” [ _although it may be for some individuals_ ]

_Successful strategies in an evolutionary game are those that make more than the average number of replicas in the next period_ either because 

* they are favored in the process by which people learn new strategies, or 
* the genotypes expressing the strategies are induced to proliferate by the process of natural selection.



# Dynamical Systems

We [use] two major types of dynamical systems, 

1. a continuous time system using differential equations, and 
2. a discrete time system using Markov chains

An equilibrium of this dynamical system, also called a critical point or fixed point, or stationary point.  at an equilibrium, dx=dt = dy=dt = 0, so the dynamical system remains forever at (x*; y*) once it reaches there. Under what conditions does a dynamical system move toward an equilibrium?

Very few dynamical systems, even simple ones in two dimensions, can be solved analytically, so the paths x(t) and y(t) cannot be written in closed form. Nevertheless, there are well-developed methods for determining when an equilibrium is stable, unstable, or neutrally stable, using tools from algebra and calculus


A finite Markov chain is a dynamical system that can be in any of n states (s<sub>1</sub>, …, s<sub>n</sub>), and if the system is in state i in time period t, it will be in state j in time period t+1 with probability p<sub>ij</sub> . Of course, for this to make sense, we must have p<sub>ij</sub> ≥ 0 for all i, j = 1, …, n, and Sum<sup>n</sup><sub>j=1</sub> (p<sub>ij</sub>) = 1. Statistical estimates of these probabilities, based on thousands of implementations of our model, for example, are the basis of our calculation of the vector field ... giving the movement of the population among the states indicating various frequencies of altruists and of parochials.

When a Markov chain has the property that the average fraction of time in each state in the long run is independent from the starting state, we say the system is ergodic, and we call the resulting long-run distribution of probabilities the stationary distribution of the Markov chain.

### A5 The Replicator Dynamic

The most natural dynamic to apply to an evolutionary game is the **replicator dynamic**

it can be shown that _every equilibrium of an evolutionary game under the replicator dynamic is a Nash equilibrium of the stage game_. This shows that the Nash equilibrium criterion remains powerful even without assuming that players are rational (i.e., that they choose best responses) or coordinated.

Maynard Smith developed the stronger notion of an **evolutionarily stable strategy**: i.e., a whole population using that strategy cannot be invaded by a small group playing any other strategy
A6 Continuation Probability and Time Discount Factor
A7 Alternatives to the Standing Model
A8 The Prisoner’s Dilemma with Public and Private Signals

[ tl;dr : _the private nature of signals is what makes it a dilemma_ ]



≠ 
≥
≤


